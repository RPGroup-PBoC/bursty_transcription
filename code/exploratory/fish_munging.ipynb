{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "import re #regex\n",
    "\n",
    "import bebi103\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "import bokeh_catplot\n",
    "\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Munging\n",
    "Load data from Brewster, pre-tidied by Manuel, and drop the spurious column that was the index in csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fish = pd.read_csv(\"../../data/jones_brewster_2014.csv\")\n",
    "del df_fish['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fish.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at everything we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = {\n",
    "    \"x_axis_label\": \"counts\",\n",
    "    \"y_axis_label\": \"expt\",\n",
    "    \"width\": 500,\n",
    "    \"height\": 1000,\n",
    "    \"horizontal\": True,\n",
    "}\n",
    "p = bokeh_catplot.box(data=df_fish, cats=\"experiment\", val=\"mRNA_cell\", **plot_kwargs)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what are all the experiment labels in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_expt_labels = df_fish['experiment'].unique()\n",
    "raw_expt_labels.sort()\n",
    "raw_expt_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, is this the complete dataset, with constitutive promoters _and_ LacI regulated measurements? Then what is in the regulated file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_csv(\"../../data/jones_brewster_regulated_2014.csv\")\n",
    "reg_labels = df_reg['experiment'].unique()\n",
    "reg_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uuuuuh, what? Is that duplicates of what's in the main dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_reg[df_reg['experiment'] == 'O3_10ngmL']))\n",
    "print(len(df_fish[df_fish['experiment'] == 'O3_10ngmL']))\n",
    "print(len(df_reg[df_reg['experiment'] == 'Oid_0p5ngmL']))\n",
    "print(len(df_fish[df_fish['experiment'] == 'Oid_0p5ngmL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the contents of the regulated file either duplicate or are a subset of the contents of the other file... Let's write a quick test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_counts_subset(subset_series, total_series):\n",
    "    subset_vals, subset_counts = np.unique(subset_series, return_counts=True)\n",
    "    total_vals, total_counts = np.unique(total_series, return_counts=True)\n",
    "    for i, val in enumerate(subset_vals):\n",
    "        assert val in total_vals, \"%r not found in total_series\" % val\n",
    "        assert (\n",
    "            subset_counts[i] <= total_counts[np.searchsorted(total_vals, val)]\n",
    "        ), \"More occurances of %r in subset_series than in total_series!\" % val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_counts_subset([0,1], [0,1,1]) # passes\n",
    "# check_counts_subset([0,1,2], [0,1,1]) # fails\n",
    "# check_counts_subset([0,1,2,3], [0,1,2,4]) # fails\n",
    "check_counts_subset([0,0,1,2,3,3,3], [0,0,1,2,3,4,4,3,3]) # passes\n",
    "# check_counts_subset([0,0,1,2,3,3], [0,0,1,2,4,3]) # fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work. Now use it for reals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_counts_subset(df_reg[df_reg[\"experiment\"] == \"Oid_0p5ngmL\"]['mRNA_cell'],\n",
    "                    df_fish[df_fish[\"experiment\"] == \"Oid_0p5ngmL\"]['mRNA_cell'])\n",
    "check_counts_subset(df_reg[df_reg[\"experiment\"] == \"O3_10ngmL\"]['mRNA_cell'],\n",
    "                    df_fish[df_fish[\"experiment\"] == \"O3_10ngmL\"]['mRNA_cell'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No assertions raised so the contents of the regulated file are in fact a subset of the full dataframe.\n",
    "So, I dunno what happened with the regulated file, but I think we can ignore it and work only with the main file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energies\n",
    "Next, let's get the energies from the supplement of Brewster/Jones 2012 paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energies = pd.read_csv(\"../../data/brewster_jones_2012.csv\")\n",
    "df_energies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are all the promoters in the 2012 dataset in the 2014 fish dataset? These are the only constitutive promoters I'm interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(item in df_fish.experiment.unique() for item in df_energies.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into regulated & constitutive data\n",
    "Some of these datasets are not of interest right now so let's split it into multiple dataframes for easier downstream handling. The regulated datasets start with O1, O2, or O3. Everything else doesn't. From that everything else, grab the ones that we have energies for, and set aside the rest. Use regex to parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all strings that start w/ 'O' in one list\n",
    "regulated_labels = [label for label in raw_expt_labels if re.match('^O', label)]\n",
    "# and put all the others in another list\n",
    "other_labels = [label for label in raw_expt_labels if not re.match('^O', label)]\n",
    "# from that, split out those we have energies for...\n",
    "constitutive_labels = [label for label in other_labels if label in tuple(df_energies.Name)]\n",
    "# ...and those we don't\n",
    "leftover_labels = [label for label in other_labels if label not in tuple(df_energies.Name)]\n",
    "leftover_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without more metadata, I don't really know what to do with the leftover labels data, e.g., what good does the aTc concentration do me if I don't know what promoter it was for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter estimation\n",
    "\n",
    "#### Chi-by-eye to sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UV5, 5DL10, and 5DL20 look like good candidates for a closer look; all have decent non-zero expression, and they look different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice = df_fish.query(\"experiment == 'UV5' \\\n",
    "                          or experiment == '5DL10' \\\n",
    "                          or experiment == '5DL20'\")\n",
    "\n",
    "df_slice['experiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a more manageable set, let's make ECDFs and chi-by-eye with negative binomial. `scipy.stats` convention is `cdf(k, n, p, loc=0)`, where $n$ is the number of successes we're waiting for and $p$ is probability of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bokeh_catplot.ecdf(data=df_slice, cats='experiment', val='mRNA_cell', style='staircase')\n",
    "# compute upper bound for theoretical CDF plots\n",
    "u_bound = max(df_slice['mRNA_cell'])\n",
    "x = np.arange(u_bound+1)\n",
    "p.line(x, st.nbinom.cdf(x, 5, 0.2))\n",
    "p.line(x, st.nbinom.cdf(x, 3, 0.4), color='orange')\n",
    "p.line(x, st.nbinom.cdf(x, .3, 0.26), color='green')\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we're in the neighborhood, so next let's treat the model more carefully with Stan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
