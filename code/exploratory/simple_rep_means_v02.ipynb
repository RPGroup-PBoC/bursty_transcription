{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re #regex\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cmdstanpy\n",
    "import arviz as az\n",
    "\n",
    "import bebi103\n",
    "import bokeh_catplot\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "# import bokeh.models.mappers\n",
    "# import bokeh.palettes\n",
    "\n",
    "import holoviews as hv\n",
    "import holoviews.operation.datashader\n",
    "hv.extension('bokeh')\n",
    "bebi103.hv.set_defaults()\n",
    "\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "%load_ext blackcellmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and parse into convenient dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fish = pd.read_csv(\"../../data/jones_brewster_2014.csv\")\n",
    "del df_fish['Unnamed: 0']\n",
    "\n",
    "raw_expt_labels = df_fish['experiment'].unique()\n",
    "\n",
    "# put all strings that start w/ 'O' in one list; these are the regulated expts\n",
    "regulated_labels = [label for label in raw_expt_labels if re.match('^O', label)]\n",
    "\n",
    "# finally create the actual useful df's\n",
    "df_reg = df_fish[df_fish['experiment'].isin(regulated_labels)]\n",
    "df_reg = df_reg.sort_values(by=['experiment']).reset_index()\n",
    "del df_reg['index']\n",
    "df_UV5 = df_fish[df_fish[\"experiment\"] == \"UV5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the regulated data, the `experiment` label combines operator sequence and aTc concentration into a single string, e.g., `Oid_2ngmL`. This is useless for Stan, so let's create new columns containing index codes for operator & aTc concentrations separately, and then attach those new columns to the regulated dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_lookup = {'O1': 1, 'O2': 2, 'O3': 3, 'Oid': 4}\n",
    "def get_op(label):\n",
    "    return op_lookup[re.split('_', label)[0]]\n",
    "\n",
    "atc_lookup = {'0p5ngmL': 1, '1ngmL': 2, '2ngmL': 3, '10ngmL': 4}\n",
    "def get_conc(label):\n",
    "    return atc_lookup[re.split('_', label)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_series = df_reg['experiment'].apply(get_op)\n",
    "op_series.name = 'op_idx'\n",
    "aTc_series = df_reg['experiment'].apply(get_conc)\n",
    "aTc_series.name = 'aTc_idx'\n",
    "\n",
    "df_reg = df_reg.join([op_series, aTc_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_reg[(df_reg['op_idx'] == 4) & (df_reg['aTc_idx'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_reg[df_reg['experiment'] == 'Oid_0p5ngmL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. That seems to have worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the previous analysis but more principled: define a binding E for each operator, a lacI copy number for each aTc concentration, and a burst freq & size (so 10 model parameters total). Fit UV5 plus _all_ the repressed data together, rather than 1 by 1. This will be a stronger test: can the burst parameters agree with constitutive UV5 and still accommodate all the repressed data, and do we recover binding energies that look remotely plausible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior predictive check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior_pred = dict(\n",
    "    N=len(df_reg),\n",
    "    N_uv5=len(df_UV5),\n",
    "    aTc_idx=df_reg.aTc_idx.values,\n",
    "    op_idx=df_reg.op_idx.values,\n",
    "#     mRNA_uv5=df_UV5[\"mRNA_cell\"].values.astype(int),\n",
    "#     ppc=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.clean_cmdstan(path='./stan/')\n",
    "sm_prior_pred = cmdstanpy.CmdStanModel(stan_file=\"stan/simple_rep_means_v02_prior_pred.stan\")\n",
    "# print(sm.code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_pred_samples = sm_prior_pred.sample(\n",
    "    data=data_prior_pred,\n",
    "    fixed_param=True,\n",
    "    sampling_iters=1000,\n",
    "#     output_dir=\"./stan/stan_samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ArviZ InferenceData\n",
    "prior_pred_samples = az.from_cmdstanpy(\n",
    "    posterior=prior_pred_samples,\n",
    "    prior=prior_pred_samples,\n",
    "    prior_predictive=['mRNA_uv5', 'mRNA']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First prior predictive for UV5 alone. Make prior fairly tight to enforce prior inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bebi103.viz.predictive_ecdf(\n",
    "    prior_pred_samples.prior_predictive['mRNA_uv5'],\n",
    "    frame_height=250,\n",
    "    frame_width=350,\n",
    "    discrete=True,\n",
    "    percentiles=(95, 90, 75, 50),\n",
    "    x_axis_label='mRNA counts',\n",
    "    x_axis_type='log'\n",
    ")\n",
    "p = bokeh_catplot.ecdf(data=df_UV5, val='mRNA_cell', style='staircase', palette=('#FF9900',), p=p)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanna make sure I haven't done anything stupid such that priors exclude the actual data. So make a panel explorer that plots prior predictive ECDFs for each experiment w/ data overlaid, and a slider to choose expt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create expt selector drop-down list\n",
    "aTc_op_selector = pn.widgets.DiscreteSlider(\n",
    "    name=\"trial\",\n",
    "    options=sorted(list(df_reg[\"experiment\"].unique())),\n",
    "    value=\"O1_0p5ngmL\",\n",
    ")\n",
    "\n",
    "@pn.depends(aTc_op_selector.param.value)\n",
    "def prior_pred_explorer(expt_label):\n",
    "    bool_slice = np.array(df_reg[\"experiment\"] == expt_label)\n",
    "\n",
    "    p = bebi103.viz.predictive_ecdf(\n",
    "        prior_pred_samples.prior_predictive[\"mRNA\"].sel(mRNA_dim_0=bool_slice),\n",
    "        frame_height=250,\n",
    "        frame_width=350,\n",
    "        discrete=True,\n",
    "        percentiles=(95, 90, 75, 50),\n",
    "        x_axis_label=\"mRNA counts\",\n",
    "        x_axis_type=\"log\",\n",
    "    )\n",
    "    p = bokeh_catplot.ecdf(data=df_reg[bool_slice],\n",
    "                           val=\"mRNA_cell\",\n",
    "                           style=\"staircase\",\n",
    "                           palette=(\"#FF9900\",),\n",
    "                           p=p\n",
    "    )\n",
    "    return p\n",
    "\n",
    "pn.Row(prior_pred_explorer, pn.Spacer(width=15), aTc_op_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly look fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.deepcopy(data_prior_pred)\n",
    "data[\"mRNA\"] = df_reg[\"mRNA_cell\"].values.astype(int)\n",
    "data[\"mRNA_uv5\"] = df_UV5[\"mRNA_cell\"].values.astype(int)\n",
    "data[\"ppc\"] = 0\n",
    "\n",
    "bebi103.stan.clean_cmdstan(path='./stan/')\n",
    "sm = cmdstanpy.CmdStanModel(stan_file=\"stan/simple_rep_means_v02.stan\")\n",
    "# print(sm.code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = sm.sample(data=data, cores=4)\n",
    "posterior_samples = az.from_cmdstanpy(posterior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.check_all_diagnostics(posterior_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. Corner plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(\n",
    "    bebi103.viz.corner(\n",
    "        posterior_samples,\n",
    "#         pars=[\"op_E[0]\", \"log_R[0]\", \"op_E[1]\", \"log_R[1]\", \"alpha\", \"b\",],\n",
    "        pars=[\"op_E[0]\", \"op_E[1]\", \"op_E[2]\", \"log_R[0]\", \"log_R[1]\",\"log_R[2]\",],\n",
    "#         pars=[\"op_E[1]\", \"op_E[2]\", \"op_E[3]\", \"log_R[1]\",\"log_R[2]\", \"log_R[3]\", ],\n",
    "        alpha=0.1,\n",
    "        xtick_label_orientation=np.pi / 4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As feared, the concentration scaling factors are totally degenerate with the binding energies.\n",
    "It's tempting to say this doesn't matter, this model just doesn't work, and move to the harder model & infer rates. But I think this is foolish: I expect the posterior predictives to fail, but despite that I still oughta be able to get better posterior shrinkage than this. I blame the degeneracy b/w copy number & affinity, which won't go away in the harder version, if anything it'll be worse, so if I can't tame it here, it won't be easier there when I don't even know what to expect and can't use tight priors to help stabilize things...\n",
    "\n",
    "One test would be to throw out a few of the trials, i.e., does it help to remove the data that are clearly way overdisperse &/or too repressed? Not that that data is bad: it actually might be the _most_ useful for inferring kinetics, but since those distributions are clearly not negative binomially distributed, it's hard to trust the inferences produced from shoving a square peg in a round hole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I think fitting for $R$ isn't gonna work. We need to specify it a priori, I think best way is with a very informative prior rather than a point estimate.\n",
    "\n",
    "Table S3 in Jones/Brewster 2014 quotes lacI copy # of 0.21, 5.9, and 50 for aTc concentrations of 0.5, 2, & 10 ng/mL, respectively. My guesstimate inference from taking binding energies as known & fitting $R$ gave the following $R$ values:\n",
    "\n",
    "|     | 0.5 ng/ml | 1 ng/ml | 2 ng/ml | 10 ng/ml |\n",
    "| --- | --------- | ------- | ------- | -------- |\n",
    "| Oid | 0.03      | 1.5     | 11      | -        |\n",
    "| O1  | 0.1       | 6       | 30-35   | -        |\n",
    "| O2  | 0.5-1     | 6-8     | 25-35   | 70-100   |\n",
    "| O3  | -         |  -      | > 25    | > 30?    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's take\n",
    "\n",
    "|     | 0.5 ng/ml | 1 ng/ml | 2 ng/ml | 10 ng/ml |\n",
    "| --- | --------- | ------- | ------- | -------- |\n",
    "| R   | 0.1       | 2       | 10      | 50       |\n",
    "| ln R| -2.3      | 0.7     | 2.3     | 3.9      |\n",
    "\n",
    "which is not far from the peaks I was using before, but now let's make the width much tighter, say 0.25 ln units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, a highly informative prior on $R$ does in fact work to make inferences of $\\Delta\\epsilon$s identifiable, and the values are in the neighborhood though not in perfect agreement with the canonical values. Maybe I should turn this around: put highly informative priors on the energies, and infer the repressor copy numbers for each aTc? Then I can use that knowledge as a prior for fitting the nonequilibrium model of repression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
