{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "import re #regex\n",
    "\n",
    "import cmdstanpy\n",
    "import arviz as az\n",
    "\n",
    "import bebi103\n",
    "import bokeh_catplot\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "# import bokeh.models.mappers\n",
    "import bokeh.palettes\n",
    "\n",
    "import holoviews as hv\n",
    "import holoviews.operation.datashader\n",
    "hv.extension('bokeh')\n",
    "bebi103.hv.set_defaults()\n",
    "\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Munging\n",
    "Load data from Brewster, pre-tidied by Manuel, and drop the spurious column that was the index in csv.\n",
    "See `code/exploratory/fish_munging.ipynb` for details. TL;DR: don't use the regulated csv, the one below has all the FISH data. mRNA_cell is the data we want, not spots_totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fish = pd.read_csv(\"../../data/jones_brewster_2014.csv\")\n",
    "del df_fish['Unnamed: 0']\n",
    "df_fish.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating out regulated data\n",
    "The regulated datasets' labels start with O1, O2, or O3. Everything else doesn't. Use regex to parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_expt_labels = df_fish['experiment'].unique()\n",
    "raw_expt_labels.sort()\n",
    "\n",
    "# put all strings that start w/ 'O' in one list\n",
    "regulated_labels = [label for label in raw_expt_labels if re.match('^O', label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves behind some data with insufficient metadata, e.g., what good does the aTc concentration do me if I don't know what promoter it was for?\n",
    "\n",
    "Now that we've got labels we want, let's slice dataframes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_fish[df_fish['experiment'].isin(regulated_labels)]\n",
    "df_UV5 = df_fish[df_fish[\"experiment\"] == \"UV5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing simple repression with Stan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan model borrows from JB's tutorial 7a, 2018, and from JB's finch beak tutorial for bebi103b 2020 TAs.\n",
    "\n",
    "The model here is the same negative binomial model we used for the constitutive case, except with the burst rate multiplied by the fold-change in mean. Can we successfully infer the Bohr parameter?\n",
    "\n",
    "As in the constitutive case, Stan parametrizes the negative binomial with $\\alpha$ and $\\zeta$, where $\\alpha$ is the burst frequency (dimensionless, nondimensionalized by mRNA lifetime) and $\\zeta = 1/b$ where $b$ is the mean burst size.\n",
    "\n",
    "What is our prior range for fold-change? Consider\n",
    "\\begin{align}\n",
    "fc = \\left( 1+\\frac{R}{N_{NS}} e^{-\\beta\\Delta\\epsilon} \\right)^{-1}\n",
    "   = \\left( 1+\n",
    "        \\exp\\left(\\ln\\left(\\frac{R}{N_{NS}}\\right)-\\beta\\Delta\\epsilon\\right)\n",
    "     \\right)^{-1}\n",
    "   = \\left( 1+ e^{-\\beta\\Delta F} \\right)^{-1}\n",
    "\\end{align}\n",
    "$R/N_{NS}$ should definitely remain between $10^{-7}$ and $10^{-2}$, and we expect/know the $\\Delta\\epsilon$ to range between about $-18$ and $-9$. So we can say $\\beta\\Delta F$ is unlikely to escape a range between $-14$ and $+7$, corresponding to fold-changes of $10^{-6}$ and $(1-10^{-3})$, which certainly already exceed our detection limits anyways. A prior such as\n",
    "\\begin{align}\n",
    "\\beta\\Delta F \\sim \\text{Normal}(\\mu=-3,\\sigma=5)\n",
    "\\end{align}\n",
    "corresponds to this story.\n",
    "\n",
    "Then our target likelihood is\n",
    "\\begin{align}\n",
    "p_m \\sim \\text{NBinom}(\\alpha, \\zeta)\n",
    "\\end{align}\n",
    "for the UV5 data, and simultaneously\n",
    "\\begin{align}\n",
    "p_m \\sim \\text{NBinom}\\left(\\frac{\\alpha}{1+ e^{-\\beta\\Delta F}}, \\zeta\\right)\n",
    "\\end{align}\n",
    "for the regulated data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_prior_predictive = cmdstanpy.CmdStanModel(\n",
    "    stan_file=\"stan/simple_rep_means_prior_predictive_v01.stan\"\n",
    ")\n",
    "# print(sm_prior_predictive.code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior_pred = dict(\n",
    "    N=len(df_UV5), \n",
    "    log_alpha_loc=0.0, \n",
    "    log_alpha_scale=2.0, \n",
    "    log_b_loc=0.5,\n",
    "    log_b_scale=1.5,\n",
    "    bohr_loc=-3.0,\n",
    "    bohr_scale=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_pred_samples = sm_prior_predictive.sample(\n",
    "    data=data_prior_pred,\n",
    "    fixed_param=True,\n",
    "    sampling_iters=1000,\n",
    "    output_dir=\"./stan/stan_samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ArviZ InferenceData\n",
    "prior_pred_samples = az.from_cmdstanpy(\n",
    "    posterior=prior_pred_samples,\n",
    "    prior=prior_pred_samples,\n",
    "    prior_predictive=['mRNA_counts']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bebi103.viz.predictive_ecdf(\n",
    "    prior_pred_samples.prior_predictive['mRNA_counts'],\n",
    "    frame_height=250,\n",
    "    frame_width=350,\n",
    "    discrete=True,\n",
    "    percentiles=(95, 90, 75, 50),\n",
    "    x_axis_label='mRNA counts',\n",
    "    x_axis_type='log'\n",
    ")\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation-based calibration\n",
    "\n",
    "Next up: simulation-based calibration (SBC). Quoting JB, this checks \"that the sampler can effectively sample the entire space of parameters covered by the prior.\" We'll go ahead and set up the data for the posterior, even though we won't be sampling the posterior right now. Then we can set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rep_test = copy.deepcopy(data_prior_pred)\n",
    "del data_rep_test[\"N\"]\n",
    "df_rep_test = df_reg[df_reg['experiment'] == 'Oid_2ngmL']\n",
    "data_rep_test[\"N_cells_uv5\"] = len(df_UV5)\n",
    "data_rep_test[\"N_cells_rep\"] = len(df_rep_test)\n",
    "data_rep_test[\"mRNA_counts_uv5\"] = df_UV5[\"mRNA_cell\"].values.astype(int)\n",
    "data_rep_test[\"mRNA_counts_rep\"] = df_rep_test[\"mRNA_cell\"].values.astype(int)\n",
    "data_rep_test[\"ppc\"] = 0\n",
    "\n",
    "sm = cmdstanpy.CmdStanModel(stan_file=\"stan/simple_rep_means_v01.stan\")\n",
    "# print(sm.code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_There's currently some bug with my call to sbc here that I can't find to save my life. I think it's just a typo somewhere but... Error message suggests it's in the python wrapper, not in the Stan code, and also b/c posterior sampling later on works fine._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sbc_output = pd.read_csv(\"stan/sbc_simple_rep_means_v01.csv\")\n",
    "except:\n",
    "    sbc_output = bebi103.stan.sbc(\n",
    "        prior_predictive_model=sm_prior_predictive,\n",
    "        posterior_model=sm,\n",
    "        prior_predictive_model_data=data_prior_pred,\n",
    "        posterior_model_data=data_rep_test,\n",
    "        measured_data=[\"mRNA_counts_uv5\", \"mRNA_counts_rep\"],\n",
    "        parameters=[\"alpha\", \"b\", \"bohr\"],\n",
    "        sampling_kwargs={'thin': 10},\n",
    "        cores=4,\n",
    "        N=400,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "\n",
    "    sbc_output.to_csv(\"stan/sbc_simple_rep_means_v01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ECDFs of the rank statistics, which should be ~ uniform. Color according to warning code, which will also let us know if there were any issues with divergences, R-hat, EBFMI, effective number of steps, or tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [\n",
    "    bokeh_catplot.ecdf(\n",
    "        data=sbc_output.loc[sbc_output[\"parameter\"] == param, :],\n",
    "        val=\"rank_statistic\",\n",
    "        cats=\"warning_code\",\n",
    "        kind=\"colored\",\n",
    "        frame_width=400,\n",
    "        frame_height=150,\n",
    "        title=param,\n",
    "        conf_int=True,\n",
    "    )\n",
    "    for param in sbc_output[\"parameter\"].unique()\n",
    "]\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot(plots, ncols=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning code 2 means R-hat failure. Let's look at the R-hat values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(\n",
    "    bokeh_catplot.ecdf(data=sbc_output, val=\"Rhat\", cats=\"parameter\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are a substantial fraction of Rhats above the brightline 1.01, JB suggests that more samples from the posterior might be wise.\n",
    "\n",
    "JB also has a nice helper function to plot the difference from uniform of rank ECDFs, with a confidence interval for the uniform distribution to guide the eye. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.sbc_rank_ecdf(sbc_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's check shrinkage and z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Points(\n",
    "    data=sbc_output,\n",
    "    kdims=['shrinkage', 'z_score'],\n",
    "    vdims=['parameter', 'ground_truth', 'mean', 'sd'],\n",
    ").opts(\n",
    "    color='parameter',\n",
    "    alpha=0.3,\n",
    "    xlim=(0, 1.05),\n",
    "    tools=['hover']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the Posterior\n",
    "We already finished building the model in order to do SBC. Now we just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do want posterior predictive checks this time\n",
    "data_rep_test[\"ppc\"] = 1\n",
    "\n",
    "posterior_samples = sm.sample(data=data_rep_test, cores=5)\n",
    "posterior_samples = az.from_cmdstanpy(\n",
    "    posterior_samples, posterior_predictive=[\"mRNA_counts_uv5_ppc\", \"mRNA_counts_rep_ppc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.check_all_diagnostics(posterior_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, no sampler warnings. Let's visualize the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(\n",
    "    bebi103.viz.corner(\n",
    "        posterior_samples,\n",
    "        pars=[\"alpha\", \"b\", \"bohr\"],\n",
    "        alpha=0.1,\n",
    "        xtick_label_orientation=np.pi / 4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks quite reasonable. The transcripts per burst & burst frequency are both comparable to what we would have inferred from Manuel's MCMC, and also what we inferred from UV5 data alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictive checks\n",
    "\n",
    "Even though the posterior looks ok, the model could still be wrong: it is identifiable, but is it consistent with the data? Posterior predictive checks address this by asking whether the model could plausibly generate the observed data. (Function borrowed from JB's finch beak tutorial for bebi103b 2020 TAs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppc_ecdf_pair(posterior_samples, ppc_var, df, percentiles=(80, 60, 40, 20),\n",
    "                 x_axis_label=\"mRNA counts per cells\", frame_width=200, frame_height=200):\n",
    "    \"\"\"Plot posterior predictive ECDFs.\"\"\"\n",
    "    n_samples = (\n",
    "        posterior_samples.posterior_predictive.dims[\"chain\"]\n",
    "        * posterior_samples.posterior_predictive.dims[\"draw\"]\n",
    "    )\n",
    "\n",
    "    p1 = bebi103.viz.predictive_ecdf(\n",
    "        posterior_samples.posterior_predictive[ppc_var].values.reshape(\n",
    "            (n_samples, len(df))\n",
    "        ),\n",
    "        data=df[\"mRNA_cell\"],\n",
    "        percentiles=percentiles,\n",
    "        discrete=True,\n",
    "        x_axis_label=x_axis_label,\n",
    "        frame_width=frame_width,\n",
    "        frame_height=frame_height\n",
    "    )\n",
    "\n",
    "    p2 = bebi103.viz.predictive_ecdf(\n",
    "        posterior_samples.posterior_predictive[ppc_var].values.reshape(\n",
    "            (n_samples, len(df))\n",
    "        ),\n",
    "        data=df[\"mRNA_cell\"],\n",
    "        percentiles=percentiles,\n",
    "        discrete=True,\n",
    "        x_axis_label=x_axis_label,\n",
    "        frame_width=frame_width,\n",
    "        frame_height=frame_height,\n",
    "        diff=True,\n",
    "    )\n",
    "    p1.x_range = p2.x_range\n",
    "    \n",
    "    return [p1, p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc_plots = (ppc_ecdf_pair(posterior_samples, \"mRNA_counts_uv5_ppc\", df_UV5),\n",
    "             ppc_ecdf_pair(posterior_samples, \"mRNA_counts_rep_ppc\", df_rep_test))\n",
    "\n",
    "# flatten list of lists w/ list comp, then plot\n",
    "ppc_plots = [subplot for sublist in ppc_plots for subplot in sublist]\n",
    "bokeh.io.show(bokeh.layouts.gridplot(ppc_plots, ncols=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on which lac operator and aTc concentration we analyze, I'd draw rather different conclusions. Let's just analyze everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling all the data\n",
    "Let's repeat for all the operators and repressor copy numbers! Since we have so many, do separate loops to generate the samples and generate viz (so we can tweak viz without pointlessly rerunning the sampling). Put all the samples in a dict for easy access; I'm not sure if arviZ will keep them in ram, but model is small enough that even if so, it'll be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress many lines of cmdstanpy output, uncomment if you want to watch it sample\n",
    "all_samples = {}\n",
    "for trial in df_reg[\"experiment\"].unique():\n",
    "    temp_df = df_reg[df_reg[\"experiment\"] == trial]\n",
    "    data = copy.deepcopy(data_prior_pred)\n",
    "    data[\"N_cells_uv5\"] = len(df_UV5)\n",
    "    data[\"N_cells_rep\"] = len(temp_df)\n",
    "    data[\"mRNA_counts_uv5\"] = df_UV5[\"mRNA_cell\"].values.astype(int)\n",
    "    data[\"mRNA_counts_rep\"] = temp_df[\"mRNA_cell\"].values.astype(int)\n",
    "    data[\"ppc\"] = 1\n",
    "\n",
    "    posterior_samples = sm.sample(data=data, cores=6)\n",
    "    all_samples[trial] = az.from_cmdstanpy(\n",
    "        posterior_samples,\n",
    "        posterior_predictive=[\"mRNA_counts_uv5_ppc\", \"mRNA_counts_rep_ppc\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always wise to check diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for trial in all_samples:\n",
    "#     print(trial)\n",
    "#     bebi103.stan.check_all_diagnostics(all_samples[trial])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some run-to-run variation. Sometimes one or two promoters give Rhat warnings a bit over 1.01, but generally this looks ok.\n",
    "\n",
    "Now that we've sampled we can plot. (I can't figure out how to add titles to the bokeh layouts that `viz.corner` returns, so I'm doing the poor man's version for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in all_samples:\n",
    "    print(trial)\n",
    "    # plot posterior as corner plot\n",
    "    bokeh.io.show(\n",
    "        bebi103.viz.corner(\n",
    "            all_samples[trial],\n",
    "            pars=[\"alpha\", \"b\", \"bohr\"],\n",
    "            alpha=0.1,\n",
    "            xtick_label_orientation=np.pi / 4,\n",
    "        )\n",
    "    )\n",
    "    # setup post pred ecdfs\n",
    "    ppc_plots = (\n",
    "        ppc_ecdf_pair(all_samples[trial], \"mRNA_counts_uv5_ppc\", df_UV5),\n",
    "        ppc_ecdf_pair(\n",
    "            all_samples[trial],\n",
    "            \"mRNA_counts_rep_ppc\",\n",
    "            df_reg[df_reg[\"experiment\"] == trial],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # flatten list of lists to prepare for gridplot\n",
    "    ppc_plots = [subplot for sublist in ppc_plots for subplot in sublist]\n",
    "    bokeh.io.show(bokeh.layouts.gridplot(ppc_plots, ncols=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, obviously this model is not \"true.\" But it's not a bad zeroth-order model for simple repression: it provides an interesting way to link the thermodynamic model (Bohr parameter) to observables beyond means.\n",
    "\n",
    "And once again this model performs better than I'd expect it to, and it's failure mode is very enlightening. It is _extremely_ interesting that for the very weakly repressed and the very highly repressed conditions, the joint posteriors on $\\alpha$ and $b$ (i.e., after marginalizing away Bohr) are _very_ similar to the posterior we got from the UV5 data alone. In these limits, approximating the distribution as still being negative binomial with a rescaled burst rate seems alright. Another statement of this: in these limits, there is still only one timescale in sight: the burst rate, appropriately scaled.\n",
    "\n",
    "In the intermediate regime, this is not true: the repressed mRNA distributions are substantially more disperse than constitutive UV5. The model can't fit both dists simultaneously, so it contorts itself to try and split the difference. `Oid0p5ngmL` is probably the most extreme example. $\\alpha$ gets pulled down and $b$ gets pulled up to increase the variance, resulting in posterior predictive distributions that are too wide for UV5 and still too narrow for the repressed data.\n",
    "\n",
    "This is actually _a good sign_: the addition of repressor leaves a nontrivial imprint on the mRNA distribution. So a kinetic model with repressor dynamics may actually be identifiable. The question is whether, even if we can infer 2 rates and label them $k_R^+$ and $k_R^-$, do they actually correspond to the microscopic repressor kinetics, or are they just related to cell cycle or mRNA lifetimes or TetR partitioning imprecision or or...? But we'll cross that bridge when we get there..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferring repressor copy number\n",
    "If we take the binding energies of each operator as knowns, we can extract $R/N_{NS}$ for each op/aTc pair and see if they make sense. First collect the approximate MAP of the Bohr parameter (in $kT$) for each trial, tabulated below.\n",
    "\n",
    "Inferred Bohr parameters:\n",
    "\n",
    "|     | 0.5 ng/ml | 1 ng/ml | 2 ng/ml | 10 ng/ml |\n",
    "| --- | --------- | ------- | ------- | -------- |\n",
    "| Oid | 1.2       | -2.75   | -4.8    | -4.4     |\n",
    "| O1  | 2.5       | -1.8    | -3.45   | -3.6     |\n",
    "| O2  | 1.8       | -0.5    | -1.8    | -2.8     |\n",
    "| O3  | ?         | > 3     | > 2.5   | 2 ?      |\n",
    "\n",
    "Then using\n",
    "\\begin{align}\n",
    "\\Delta F = \\Delta \\epsilon - \\ln(R/N_{NS})\n",
    "\\end{align}\n",
    "and\n",
    "\\begin{align}\n",
    "\\Delta \\epsilon_{Oid} = -17.7 \\\\\n",
    "\\Delta \\epsilon_{O1}  = -15.3 \\\\\n",
    "\\Delta \\epsilon_{O2}  \\in (-13.9, -13.6) \\\\\n",
    "\\Delta \\epsilon_{O3}  \\in (-9.7, -9.4) \\\\\n",
    "\\end{align}\n",
    "we get estimates for $R$.\n",
    "\n",
    "Inferred $R$:\n",
    "\n",
    "|     | 0.5 ng/ml | 1 ng/ml | 2 ng/ml | 10 ng/ml |\n",
    "| --- | --------- | ------- | ------- | -------- |\n",
    "| Oid | 0.03      | 1.5     | 11      | -        |\n",
    "| O1  | 0.1       | 6       | 30-35   | -        |\n",
    "| O2  | 0.5-1     | 6-8     | 25-35   | 70-100   |\n",
    "| O3  | -         |  -      | > 25    | > 30?    |\n",
    "\n",
    "We have left blank values where the Bohr parameter was clearly inferred poorly (either very strong or very weak repression), which would result in obviously inaccurate estimates of $R$. Even the values listed should be taken with a grain of salt, but this gives us an order of magnitude sense of things.\n",
    "\n",
    "Strangely, though, Brewster and Daniel were using HG203 as a base just as I am, with _tetR_ integrated at the _gspI_ locus and _lacI_ at _ybcN_. The only difference is the reporter at _galK_ and the mNeonGreen fusion. So that means our aTc induction levels ought to be approximately apples to apples, no? Why do I seem to get $\\sim1$ order of magnitude stronger induction?? Or maybe my estimates here are just that sloppy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next step\n",
    "\n",
    "So we can fit each new repressor copy number & operator combo with it's own _de novo_ Bohr parameter & that is an easily identifiable model. Good.\n",
    "\n",
    "Can we be more principled? For the next iteration of the model, let's define a binding energy for each operator and a single fit parameter that globally converts from aTc to lacI copy number (assume they're linearly proportional). Fit all the data at once. Now there's only one global $\\alpha$ and $b$; how will they adapt? And can we recover, at least approximately, the known operator binding energies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For coding the full true likelihood, JB suggests referring to a JavaScript library of special functions, by paulmasson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
