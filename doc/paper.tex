\documentclass[12pt]{article}%{amsart}
\usepackage[top = 1.0in, bottom = 1.0in, left = 1.0in, right = 1.0in]{geometry}
% See geometry.pdf to learn the layout options. There are lots.
%\geometry{letterpaper}               % ... or a4paper or a5paper or ...
%\geometry{landscape}             % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
%\usepackage{epstopdf}
% \usepackage{caption}
\usepackage{amsmath}
% \usepackage{longtable}
% \usepackage{tabu}
% \usepackage{accents} %to get undertildes for vec & mat
\usepackage{color} % for colored text
% \usepackage[normalem]{ulem} % for editing: striking out text using 'sout' command

% \newcommand\mytablefigwidth{0.35\textwidth}

% allows to use .ai files directly w/o resaving as pdf
\DeclareGraphicsRule{.ai}{pdf}{.ai}{}

% Handy math macros!
\newcommand{\vect}[1]{\vec{#1}}
\newcommand{\matr}[1]{\mathbf{#1}}
\newcommand{\rate}[3]{{#1}_{#2}^{#3}}
\newcommand{\mmnote}[1]{\textcolor{cyan}{(MM:~#1)}}

% derivative macros. these are sneaky. the [{}] is an empty default 1st arg
% usage: provide 1 arg: \deriv{x} gives d/dx
% provide 2 args like so: \deriv[f]{x} gives df/dx
\newcommand{\deriv}[2][{}]{\frac{d #1}{d #2}}
\newcommand{\pderiv}[2][{}]{\frac{\partial #1}{\partial #2}}
\newcommand{\psecderiv}[2][{}]{\frac{\partial{^2} #1}{\partial #2{^2}}}

%%%%% Referencing macros %%%%%
\newcommand{\fig}[1]{Figure~\ref{#1}}
\newcommand{\tref}[1]{Table~\ref{#1}}
\newcommand{\eq}[1]{Eq.~(\ref{#1})}
\newcommand{\eqrange}[2]{Eqs.~(\ref{#1}-\ref{#2})}

%%%%%
\begin{document}

\title{Simple repression draft}

\maketitle

\section{Introduction}
\mmnote{Key ideas, no particular order, that I haven't written down before:
\begin{itemize}
\item Our goal is to build phenomenological models of input-output
functions of genetic circuits. More precisely, we want phenomenology
in the sense of coarse-graining away atomistic detail, but still
retaining biophysical meaning, e.g., we don't want to coarse-grain
as far as Hill functions. Why not? We are motivated by studies
like~\cite{Razo-Mejia2020}, for which Hill functions are
insufficient. Such work requires a quantitative theory of how
biophysical changes at the molecular level propagate to
input-output functions at the genetic circuit level.
We want concepts, not mere facts.
In particular a key question is: at this level of
coarse graining, what microscopic details do I need to explicitly
model, and how do we figure that out? For example, do I need to
worry about all or even any of the steps that individual RNAPs go
through each time they make a transcript? Turning the question
around, can we see any imprint of those processes in the
available data? If the answer is no, then those processes are
irrelevant for our purposes. Forward modeling and inverse
(statistical inferential) modeling can complement each other
beautifully here.
\end{itemize}}

\fig{fig1:means_cartoons}A shows the qualitative picture of
simple repression. An operator, the binding site on the DNA for a
repressor protein, may be found occupied by a repressor, in which
case transcription is blocked from occurring. Or it may be found
unoccupied, in which case RNA polymerase (RNAP) may bind and
transcription can proceed.

The key assumption we make is that binding of repressor and RNAP in the promoter region of interest is exclusive, meaning that one or the other may bind, but never may both be simultaneously bound.
It is often imagined that when the repressor is bound to its operator,
RNAP is sterically blocked from binding to its promoter sequence.
Current evidence suggests this is sometimes, but not
always the case~\mmnote{Cite that fig, from ??Nathan or Bill or
Rob??, showing locations of repressor binding sites far upstream
of promoter}, and it remains an interesting open question precisely
how a repressor bound far upstream is able to repress transription.
Suggestions include ``action-at-a-distance'' mediated by kinks in
the DNA, formed when the repressor is bound, that prevent RNAP binding.
Nevertheless, our modeling in this work is sufficiently
coarse-grained that we simply assume exclusive binding and need
not worry about such precise details.

\mmnote{Add a notation aside somewhere that all association rates are written as zeroth-order rates. In other words, the concentration of the molecule is hidden inside, so for instance, $k_R^+$ is proportional to repressor copy number.}

\section{Means}
\subsection{Fold-changes are indistinguishable across models}
As a first stop on our search for the ``right'' model of simple
repression, let us consider what we can learn from theory and
measurements of fold-change in mean expression. The fold-change is defined as
\begin{equation}
\text{fold-change}
= \frac{\langle \text{gene expression with repressor present} \rangle}
        {\langle \text{gene expression with repressor absent} \rangle}
= \frac{\langle m\rangle(R\ne 0)}{\langle m\rangle(R = 0)}
\label{eq:fc_def}
\end{equation}
where angle brackets denote the averge over a population of cells
and mean mRNA $\langle m\rangle$ is viewed as a function of
repressor copy number $R$.
The second
equality in~\ref{eq:fc_def} follows from assuming that the
translation efficiency, i.e., the number of proteins translated
per mRNA, is the same in both conditions.
In other words, we assume that mean protein level is proportional
to mean mRNA level, and that the proportionality constant is the
same in both conditions and therefore cancels out in the ratio.
This is reasonable since the cells in the two conditions are
identical except for the presence of the transcription factor,
and it is difficult to imagine the transcription factor having
any direct effect on translation.

Fold-change has proven a very convenient observable in past
work~\cite{Garcia2011a, Razo-Mejia2018, Chure2019}.
Part of its utility in dissecting transcriptional regulation is
its ratiometric nature, which is always easier than making an
absolute measurement. Also, by measuring otherwise identical cells
with and without a transcription factor present, any biological
noise common to both conditions can be made to cancel away.

\fig{fig1:means_cartoons} depicts a smorgasbord
of mathematized cartoons for simple repression that have appeared
in previous literature. For each cartoon, we calculate the
fold-change in mean gene expression as predicted by that model,
deferring some algebraic details to the appendix.
What we will find is that all cartoons collapse to a single
master curve, shown in \fig{fig1:means_cartoons}c, which contains
just two parameters. We label the parameters $\Delta F_R$, an
effective free energy parametrizing the repressor-DNA
interaction, and $\rho$, which subsumes all details of
transcription in the absence of repressors.
We will offer some intuition for why this master curve exists and discuss
why it is likely impossible to discriminate ``right'' from ``wrong''
cartoons given only measurements of fold-changes in expression.

\mmnote{Snappy names for all these cartoons would really help the reader. Also naming them by number of promoter states is confusing to the reader because analogous models have different number of states when we're talking about constitutive version vs version with repressor. Thoughts??}

\subsubsection{Equilibrium, 2-state}
In this simplest model, the promoter is idealized as existing in
one of two states, either repressor bound or repressor unbound.
The rate of transcription, and therefore the level of gene
expression, is assumed to be proportional to the fraction of time
spent in the repressor unbound state.
Mathematically, this amounts to the statement that the mean mRNA level is
given by
\begin{equation}
\langle m \rangle = \frac{r}{\gamma}
        \left(1 + \frac{R}{N_{NS}} e^{-\beta\Delta\epsilon_R}\right)^{-1},
\end{equation}
where $r$ is the transcription rate from the repressor unbound
state, $\gamma$ is the mRNA degradation rate, $R$ is repressor
copy number, $N_{NS}$ is the number of nonspecific binding sites
in the genome (where repressors spend most of their time when not
bound to the operator, their specifc binding site),
$\beta=1/k_BT$, and $\Delta\epsilon_R$ is the binding energy of a
repressor to its operator site. The derivation of this result is deferred
to the appendix.

The fold-change is easily found as the ratio of mean mRNA with
and without repressor. This gives
\begin{equation}
\text{fold-change}
= \left(1 + \frac{R}{N_{NS}} e^{-\beta\Delta\epsilon_R}\right)^{-1},
\end{equation}
which clearly matches the form of the master curve
in~\eq{fig1:means_cartoons} with $\rho=1$.

In fact it was noted in~\cite{Chure2019} that this two-state
model can be viewed as the coarse-graining of any equilibrium
promoter model in which no transcriptionally active states have
transcription factor bound. Put differently, there is no overlap
between TF bound states and transcriptionally active states. We
will see this explicitly in the 3-state equilibrium model below,
but perhaps surprising is that something analogous carries over
even to the nonequilbrium models we consider later.

\subsubsection{Equilibrium, 3-state}
Compared to the previous model, here we fine-grain the repressor
unbound state into two separate states: empty, and RNAP bound.
This picture was used in~\cite{Garcia2011a} as we use it here,
and in~\cite{Razo-Mejia2018} and~\cite{Chure2019} it was generalized
to incorporate small-molecule inducers that bind the repressor.
Interestingly, the effect of this is simply to renormalize $R$
from the total number of repressors to a smaller effective number,
roughly (though not exactly) the number which are unbound by inducers.

The mean mRNA, as derived in the appendix from a similar
enumeration of states and weights as the previous model, is
\begin{equation}
\langle m \rangle = \frac{r}{\gamma}
\frac{\frac{P}{N_{NS}} e^{-\beta\Delta\epsilon_P}}
        {
        1 + \frac{R}{N_{NS}} e^{-\beta\Delta\epsilon_R}
        + \frac{P}{N_{NS}} e^{-\beta\Delta\epsilon_P}
        },
\end{equation}
where the new variables are $\Delta\epsilon_P$, the difference in
RNAP binding energy to its specific site (the promoter) relative
to an average nonspecific background site, and the RNAP copy
number, $P$. The fold-change again follows immediately as
\begin{align}
\text{fold-change}
&= \frac{\frac{P}{N_{NS}} e^{-\beta\Delta\epsilon_P}}
        {
        1 + \frac{R}{N_{NS}} e^{-\beta\Delta\epsilon_R}
        + \frac{P}{N_{NS}} e^{-\beta\Delta\epsilon_P}
        }
\frac{1 + \frac{P}{N_{NS}} e^{-\beta\Delta\epsilon_P}}
        {\frac{P}{N_{NS}} e^{-\beta\Delta\epsilon_P}}
\\
&= \left(
1 + \frac{\frac{R}{N_{NS}} e^{-\beta\Delta\epsilon_R}}
        {1 + \frac{P}{N_{NS}} e^{-\beta\Delta\epsilon_P}}
\right)^{-1}
\\
&= (1 + \exp(-\Delta F_R - \log\rho))^{-1},
\end{align}
with $\Delta F_R = \beta\Delta\epsilon_R - \log(R/N_{NS})$
and $\rho = 1 + \frac{P}{N_{NS}}\mathrm{e}^{-\beta\Delta\varepsilon_P}$
as shown in~\fig{fig1:means_cartoons}.

\begin{figure}%[h!]
\centering
\includegraphics[width=\textwidth]{../figures/fig1/fig1.ai}
\caption{
\textbf{
An overview of the simple repression motif at the level of means.}
(A) depicts the qualitative biological picture of simple repression.
(B) shows a variety of possible mathematized cartoons of simple
repression, along with the corresponding complexity $\rho$ of the
architecture, an effective parameter which subsumes all details
of the architecture excluding the repressor.
(C) shows the ``master curve'' to which all cartoons in (B) collapse.
}
\label{fig1:means_cartoons}
\end{figure}

\subsubsection{Nonequilibrium model 1 - Poisson promoter}
For our first kinetic model, we consider the simplest possible
picture with only two states, repressor bound and unbound.
This is exactly the model used for the main results of~\cite{Jones2014}.
In this picture, repressor association and dissociation rates
from its operator site, $k_R^+$ and $k_R^-$, respectively, govern
transitions between the two states. When the system is in the
unbound state, transcriptions initiate at rate $r$, which
represents a coarse-graining of all the downstream processes into
a single effective rate. mRNA is again degraded at rate $\gamma$.

Let $p_{m,R}(t)$ denote the joint probability of finding the
system in the repressor bound state with $m$ mRNA molecules
present at time $t$, and similarly define $p_{m,U}(t)$ for the
repressor unbound state. 
This model is governed by a master equation giving the time
evolution of $p_{m,R}(t)$ and $p_{m,U}(t)$, which is
\begin{align}
\begin{split}
\deriv{t}p_{m,R}(t) =& - k_R^- p_{m,R}(t) + k_R^+ p_{m,U}(t)
                + (m+1)\gamma p_{m+1,R}(t) - \gamma p_{m,R}(t)
\\
\deriv{t}p_{m,U}(t) =&\; k_R^- p_{m,R}(t) - k_R^+ p_{m,U}(t)
                        + rp_{m-1,U}(t) - rp_{m,U}(t)
                \\
                &+ (m+1)\gamma p_{m+1,U}(t) - \gamma p_{m,U}(t).
\end{split}
\end{align}
In each equation, the first two terms describe transitions
between promoter states due to repressors unbinding and binding,
respectively. The final two terms describe degradation of mRNA,
decreasing the copy number by one, and the terms with coefficient
$r$ describe transcription initiation increasing the mRNA copy
number by one.

We can greatly simplify the notation, which will be especially
useful for the more complicated models yet to come, by
re-expressing the master equation in vector form. The promoter
states are collected into a vector and the rate constants are
collected into matrices as
\begin{equation}
\vect{p}_m = \begin{pmatrix} p_{m,R} \\ p_{m,U} \end{pmatrix},\
\matr{K} = \begin{pmatrix} -k_R^- & k_R^+ \\ k_R^- & -k_R^+ \end{pmatrix},\
\matr{R} = \begin{pmatrix} 0 & 0 \\ 0 & r \end{pmatrix},\
\label{eq:2state_cme_matrices}
\end{equation}
so that the master equation may be condensed as
\begin{equation}
\deriv{t}\vect{p}_m(t) =
\left( \matr{K} - \matr{R} - \gamma m \matr{I} \right) \vect{p}_m(t)
                + \matr{R} \vect{p}_{m-1}(t)
                + \gamma (m+1) \matr{I} \vect{p}_{m+1}(t)
                - \gamma m \matr{I} \vect{p}_m(t),
\label{eq:2state_rep_cme}
\end{equation}
where $\matr{I}$ is the identity matrix.
Taking steady state by setting time derivatives to zero,
the mean mRNA can be found to be
\begin{equation}
\langle m \rangle = \frac{r}{\gamma}
        \left(1 + \frac{k_R^+}{k_R^-}\right)^{-1},
\end{equation}
with the algebra details again deferred to the appendix.
Recall $k_R^+$ is proportional to the repressor copy number, so
in computing fold-change, absence of repressor corresponds to
$k_R^+\rightarrow0$.
Therefore fold-change in this model is simply
\begin{equation}
\text{fold-change} = \left(1 + \frac{k_R^+}{k_R^-}\right)^{-1},
\end{equation}
again matching the master curve of~\fig{fig1:means_cartoons} with $\rho=1$.

\subsubsection{Nonequilibrium model 2 - RNAP bound/unbound states}
Analogous to the three-state equilibrium model, this model
fine-grains the repressor unbound state of nonequilbrium model 1,
resolving it into an empty promoter state and an RNAP-bound state.
Note in this picture, in contrast with model 4 below,
transcription initiation is accompanied by a promoter state
change, in keeping with the interpretation as RNAP-bound and
empty states: if an RNAP successfully escapes the promoter and
proceeds to elongation of a transcript, clearly it is no longer
bound at the promoter! Therefore another RNAP must bind before
another transcript can be initiated.

The master equation governing this model is analogous
to~\eqrange{eq:2state_cme_matrices}{eq:2state_rep_cme} for model 1 above.
The main subtlety arises since transcription initiation
accompanies a promoter state change.
This can be understood by analogy to $\matr{K}$. The
off-diagonals and diagonals of $\matr{K}$ correspond to
transitions arriving at or departing from, respectively, the
promoter state of interest. If transcription initiations are
accompanied by promoter state changes, we must have separate
matrices for arriving and departing transcription events since
the arriving and departing transitions have different initial
copy number of mRNA, unlike for $\matr{K}$ where they are the same.
The master equation for this model is
\begin{equation}
\deriv{t}\vect{p}_m(t) =
\left( \matr{K} - \matr{R_D} - \gamma m \matr{I} \right) \vect{p}_m(t)
                + \matr{R_A} \vect{p}_{m-1}(t) +
                \gamma (m+1) \matr{I} \vect{p}_{m+1}(t)
                - \gamma m \matr{I} \vect{p}_m(t),
\label{eq:3state_rep_cme}
\end{equation}
with the state vector and promoter transition matrix defined as
\begin{equation}
\vect{p}_m = \begin{pmatrix} p_{m,R} \\ p_{m,E} \\ p_{m,P} \end{pmatrix},\
\matr{K} = \begin{pmatrix} -k_R^- & k_R^+ & 0 \\
                        k_R^- & -k_R^+ -k_P^+ & k_P^- \\
                        0 & k_P^+ & -k_P^- 
                \end{pmatrix},
\label{eq:3state_cme_matrices_pt1}
\end{equation}
and the initiation matrices given by
\begin{equation}
\matr{R_A} = \begin{pmatrix}
                0 & 0 & 0 \\ 0 & 0 & r \\ 0 & 0 & 0
                \end{pmatrix},\
\matr{R_D} = \begin{pmatrix}
                0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & r
                \end{pmatrix},
\label{eq:3state_cme_matrices_pt2}
\end{equation}
The elements of $\vect{p}_m$ encode the probabilities of having
$m$ mRNA present along with the promoter having repressor bound,
being empty, or having RNAP bound, respectively.
$\matr{R_A}$ describes probability flux \textit{arriving} at the state
$\vect{p}_m$ from a state with one fewer mRNA, namely
$\vect{p}_{m-1}$, and $\matr{R_D}$ describes probability flux
\textit{departing} from the state $\vect{p}_m$
for a state with one more mRNA, namely $\vect{p}_{m+1}$.
$\matr{K}$ is closely analogous to model 1.

Mean mRNA at steady state is found analogously to model 1, with the result
\begin{equation}
\langle m\rangle = \frac{r}{\gamma}
        \frac{k_R^- k_P^+}
        {k_R^- k_P^+ + k_R^- (k_P^- + r) + k_R^+ (k_P^- + r)}.
\end{equation}
Fold-change is again found from the ratio prescribed by~\eq{eq:fc_def},
from which we have
\begin{align}
\text{fold-change}
&=      \frac{k_R^- k_P^+}
        {k_R^- k_P^+ + k_R^- (k_P^- + r) + k_R^+ (k_P^- + r)}
        \frac{k_P^+ + k_P^- + r}{k_P^+}
\\
&=      \left(1 + \frac{k_R^+}{k_R^-}
                \frac{k_P^- + r}{k_P^+ + k_P^- + r}
        \right)^{-1}
\\
&=      \left(1 + \frac{k_R^+}{k_R^-}
        \left(1 + \frac{k_P^+}{k_P^- + r}\right)^{-1}
        \right)^{-1},
\end{align}
which follows the master curve with
$\rho = 1 + k_P^+/(k_P^- + r)$ as claimed.

\subsubsection{Nonequilibrium model 3
- Multistep transcription initiation and escape}
One might reasonably complain that the first two
``nonequilbrium'' models we have considered are straw men. Their
steady states necessarily satisfy detailed balance which is
equivalent to thermodynamic equilibrium. Why is this the case? At
steady state there is by definition no net probability flux in or
out of each promoter state, but since the promoter states form a
linear chain, there is only one way in or out of the repressor
bound and RNAP bound states, implying each edge must actually
have a net zero probability flux, which is the definition of
detailed balance (usually phrased as equality of forward and
reverse transition fluxes).

Now we consider model 3 in~\eq{fig1:means_cartoons} which allows
the possibility of true nonequilibrium steady-state fluxes
through the promoter states.
We point out that this model was considered previously in~\cite{Mitarai2015}
where a comparison was made with model 1 as used in~\cite{Jones2014}.
The authors of~\cite{Mitarai2015} argued that the additional
complexity is essential to properly account for the noise in the
mRNA distribution. We will weigh in on both models later when we
consider observables beyond fold-change.

The master equation governing this model is
identical in form to model 2 above, namely
\begin{equation}
\deriv{t}\vect{p}_m(t) =
\left( \matr{K} - \matr{R_D} - \gamma m \matr{I} \right) \vect{p}_m(t)
                + \matr{R_A} \vect{p}_{m-1}(t) +
                \gamma (m+1) \matr{I} \vect{p}_{m+1}(t)
                - \gamma m \matr{I} \vect{p}_m(t),
\end{equation}
but obviously with a higher-dimensional state space and different matrices.
The state vector and promoter transition matrix are now
\begin{equation}
\vect{p}_m = \begin{pmatrix} p_{m,R} \\ p_{m,E} \\
                             p_{m,C} \\ p_{m,O}\end{pmatrix},\
\matr{K} = \begin{pmatrix} -k_R^- & k_R^+ & 0 & 0\\
                        k_R^- & -k_R^+ -k_P^+ & k_P^- & 0 \\
                        0 & k_P^+ & -k_P^- - k_O & 0 \\
                        0 & 0 & k_O & 0
                \end{pmatrix},
\end{equation}
with the four promoter states, in order, being repressor bound,
empty, RNAP closed complex, and RNAP open complex.
Besides increasing dimension by one again, the only new feature in
$\matr{K}$ is the rate $k_O$, representing the (irreversible)
rate of open complex formation from the closed complex.
The initiation matrices are given by
\begin{equation}
\matr{R_A} = \begin{pmatrix}
        0 & 0 & 0 & 0 \\ 0 & 0 & 0 & r \\ 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0
                \end{pmatrix},\
\matr{R_D} = \begin{pmatrix}
        0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0\\ 0 & 0 & 0 & r
                \end{pmatrix},
\end{equation}
again closely analogous to model 2.

The expression for mean mRNA is substantially more complicated
now, as worked out in the appendix where we find
\begin{equation}
\langle m\rangle = \frac{r}{\gamma}
        \frac{k_R^- k_P^+ k_O}
        {k_R^- [(k_P^+ (k_O + r) + r(k_P^- + k_O)] + k_R^+ r(k_P^- + k_O)},
\end{equation}
which can be simplified to
\begin{equation}
\langle m\rangle
= \frac{r}{\gamma}
\frac{\frac{k_P^+ k_O}{r(k_O + k_P^-)}}
        {1 + \frac{k_P^+ (k_O + r)}{r(k_O + k_P^-)} + \frac{k_R^+}{k_R^-}}.
\end{equation}
The strategy is to isolate the terms involving the repressor, so that now the fold-change is seen to be simply
\begin{align}
\text{fold-change}
&= \frac{\frac{k_P^+ k_O}{r(k_O + k_P^-)}}
        {1 + \frac{k_P^+ (k_O + r)}{r(k_O + k_P^-)} + \frac{k_R^+}{k_R^-}}
        \frac{1 + \frac{k_P^+ (k_O + r)}{r(k_O + k_P^-)}}
                {\frac{k_P^+ k_O}{r(k_O + k_P^-)}}
\\
&= \left(
        1 + \frac{k_R^+}{k_R^-}
        \left(1 + \frac{k_P^+ (k_O + r)}{r(k_O + k_P^-)}\right)^{-1}
\right)^{-1},
\end{align}
surprisingly reducing to the master curve once again, with
$\rho = 1 + \frac{k_P^+ (k_O + r)}{r(k_O + k_P^-)}$.

This example hints that an arbitrarily fine-grained model of
downstream transcription steps may still be collapsed to the form
of the master curve in~\fig{fig1:means_cartoons}B so long as the
repressor binding is exclusive with transcriptionally active
states. We offer this as a conjecture, and we suspect that a
careful argument using the King-Altman diagram
method~\cite{King1956, Hill1966} might furnish a ``proof.''
Our focus here is not on full generality but rather to survey an
assortment of plausible models that have been proposed in the
literature for simple repression.

\subsubsection{Nonequilibrium model 4 - ``Active'' and ``inactive'' states}
This model is at the core of the theory in~\cite{Razo-Mejia2020}.
At a glance the cartoon for this model may appear very similar to model 2,
and mathematically it is, but the interpretation is rather different.
In model 2, we interpreted the third state literally as an
RNAP-bound promoter and modeled initiation of a transcript as
triggering a promoter state change, making the hopefully
uncontroversial assumption that an RNAP can only make one
transcript at a time. In contrast, in the present model the
promoter state does \textit{not} change when a transcript is
initiated. So we no longer interpret these states as literally
RNAP bound and unbound but instead as coarse-grained ``active''
and ``inactive'' states, the details of which we leave
unspecified for now. We will comment more on this model below
when we discuss Fano factors of models.

Mathematically this model is very similar to models 1 and 2.
Like model 1, the matrix $R$ describing transcription initiation
is diagonal, namely
\begin{equation}
\matr{R} = \begin{pmatrix}
                0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & r
        \end{pmatrix}.
\end{equation}
so the master equation takes verbatim the same form as it did for model
1,~\eq{eq:2state_rep_cme}. Meanwhile the promoter transition matrix
$K$ is the same as~\eq{eq:3state_cme_matrices_pt1} from model 2,
although we relabel the rate constants from $k_P^\pm$ to $k^\pm$ to
reiterate that these are not simply RNAP binding and unbinding rates.

Carrying out the algebra, the mean mRNA can be found to be
\begin{equation}
\langle m\rangle = \frac{r}{\gamma}
\frac{k_R^- k^+}
{k_R^- k^+ + k_R^- k^- + k_R^+ k^-},
\end{equation}
and the fold-change readily follows,
\begin{align}
\text{fold-change}
&=      \frac{k_R^- k^+}{k_R^- k^+ + k_R^- k^- + k_R^+ k^-}
        \frac{k_R^- k^+ + k_R^- k^-}{k_R^- k^+}
\\
&=      \left(1 + \frac{k_R^+}{k_R^-}
                \left(1 + \frac{k^+}{k^-}\right)^{-1}
        \right)^{-1},
\end{align}
from which we see $\rho = 1 + k^+/k^-$ as shown in~\fig{fig1:means_cartoons}.

\subsubsection{Nonequilibrium model 5 - Bursty promoter}
We will have much more to say about this model in subsequent sections.
For now we sketch it as an intuitive analog to model 1,
with just two states, repressor bound or unbound, and transition rates
between them of $k_R^+$ and $k_R^-$.
In model 1, when in the unbound state, single mRNA transcripts
are produced as a Poisson process with some characteristic rate
$r$. This model by contrast produces, at some Poisson rate $k_i$,
\textit{bursts} of transcripts with a geometrically distributed
burst size and a mean burst size $b$.

From this intuitive picture and by analogy to model 1, then, it should be plausible that the mean mRNA level is
\begin{equation}
\langle m\rangle = \frac{k_i b}{\gamma}
        \left(1 + \frac{k_R^+}{k_R^-}\right)^{-1},
\end{equation}
which will turn out to be correct from a careful calculation.
For now, we simply note that just like model 1, the fold-change becomes
\begin{equation}
\text{fold-change} = \left(1 + \frac{k_R^+}{k_R^-}\right)^{-1}
\end{equation}
with $\rho=1$ also like model 1.

We will also see later how this model emerges as a natural limit of model 4.

\subsubsection{Summary and discussion of results across models for fold-changes in mean expression}
\mmnote{Key ideas:
\begin{itemize}
\item Exclusive repression and occupancy hypothesis. Not
necessarily steric hindrance, e.g., maybe kinked DNA, but it is
key that there is zero transcription when repressor is bound.
This is the key takeaway from the qualitative cartoon in Fig 1A.
\item Key assumption: expression is proportional to occupation
probability of whatever the ``active'' state is for a given
model, whatever we mean by active.
\item Also emphasize that parameters/rates are \textit{not}
apples-to-apples between cartoons, especially the initiation rate $r$.
Indeed, this is the entire point! Except for repressor
energies/rates, the other parameters are not independently
measurable or inferrable b/c we're not even sure what
steps/states we should be writing in the model!
(simple RNAP kinetics as inferred in vitro, or supercoiling, or
RNAP cluster kinetics a la Ibrahim, or maybe
gene-copy/RNAP-copy/other-copy number is really the key, or...)
So all you get are coarse-grained combos like $\rho$, and even
$\rho$ would be hard to infer, much less trying to infer its innards.
\item Emphasize that tuning any of the parameters in $\rho$ is
probably off-limits experimentally: it wrecks entire cell
physiology and confounds everything. You can write down models of
what you THINK the important steps are and aren't, and use in
vitro data for the important steps, but without any way to
experimentally perturb in vivo, you have no way to TEST whether
your modeling assumptions are correct! Also point out
supercoiling~\cite{Chong2014,Sevier2016} to emphasize that the
potential features that are necessary to include are WAY more
than just RNAP details. One possible tuning knob is maybe RNAP
binding sites, but we don't have a terrific predictive
understanding of how mutations there would influence any of the
parameters inside $\rho$, so still not obvious how to make use of
that. Brewster/Daniel2012 energy matrix is only good in one model
framework and doesn't tell you anything about how model params in
other pictures would respond.
In theory you could refit their raw data to different models, but
as we see later, even having data of full mRNA distributions is
insufficient to identify parameters in all but the simplest of
the models in Figs.\ 1 and 2, so it seems doubtful that only
measurements of means would fare better.
??Double check, what did they actually measure in 2012 paper??
\item Weak promoter corresponds to $\rho\approx 1$. In principle,
if repressor binding E or kinetics are known to high enough
precision, deviations from $\rho=1$ become a matter of expt. In
practice, I don't think it's at all realistic to measure
repressor params or expression levels precisely enough to detect
the expected tiny deviations from $\rho=1$. We can estimate: how
good would determination of $\Delta F_R$ in Fig~1B have to be to
get a given uncertainty in $\rho$? I think it's approx 1-to-1:
e.g., an uncertainty of 0.1 (kT) in $\Delta F_R$ converts to a
0.1 uncert in $\log\rho$, and since $\rho\approx 1$, that means
$\log(1+\Delta\rho)\approx\Delta\rho\approx 0.1$.
That's a really hard determination of $\Delta F_R$ for a very
coarse determination of $\rho$. Doubtful that inference of
kinetic rates would be any easier and probably a lot harder.Also,
in vitro RNAP data says $\rho\approx 1$ should be true, and even
if that's the wrong quantity to be talking about, Manuel's
inference of $k^+$ and $k^-$ suggests that still $\rho$ is close
to 1, and that inference is agnostic to the microscopics.
\item Master curve exists b/c repressor is on its own leaf of
graph. (But maybe don't use that language.) Arb noneq stuff can
happen on rest of promoter state space, doesn't matter. Is this
``one curve to rule them all'' a tautology? How do we probe the
theory? Can't do it at level of means, there's no discriminatory
power, need to go beyond. Test if free energy inferred from
fold-change measurements agrees with TF rates inferred from
single molec, and if those rates agree with rates inferred from
mRNA population distributions.
\item Here's a fun puzzle: 2-state equilibrium model gets details
of transcription so wrong, how can it be useful? Because
fold-change is a ratio! Since details all collapse into $\rho$,
fitting this 2-state model to fold-change measurements can
\textit{still} give you a not-bad estimate of ratio of repressor
rates, i.e., binding energies.
\item 
\end{itemize}
}

\section{Beyond means}
\subsection{A one-state promoter with bursting is the ``best'' model of constitutive promoters}
Before we can tackle simple repression, we need an adequate
phenomenological model of constitutive expression.
The literature abounds with options from which we can choose,
and we show several potential kinetic models for constitutive promoters
in~\fig{fig:constit_cartoons}.
Let us consider the suitability of each model for our purposes in turn.

\begin{figure}%[h!]
\centering
\includegraphics[width=0.9\textwidth]{../figures/fig1.5/fig1point5.ai}
\caption{\textbf{Constitutive promoter cartoon comparison.}
The left column depicts various plausible cartoons for constitutive promoters.
We also list literature references where models have been used previously.
In model (1), transcripts are produced in a Poisson process~\cite{Jones2014}.
Model (2) features explicit modeling of RNAP binding/unbinding
kinetics~\cite{Phillips2015a}.
Model (3) is a more detailed generalization of model (2),
treating transcription initiation as a multi-step process
proceeding through closed and open complexes~\cite{Mitarai2015}.
Model (4) is somewhat analogous to (2) except with the precise nature
of active and inactive states left ambiguous~\cite{Razo-Mejia2020}.
Finally, model (5) can be viewed as a certain limit of model (4)
in which transcripts are produced in bursts,
and initiation of bursts is a Poisson process.
\mmnote{Haven't found model 5 formulated quite like this in the literature,
usually burstiness is handled like model 4, but I should probably search a bit more.}
The right column shows the Fano factor for each model.
Note especially the crucial diagnostic: (2) and (3) have $\nu$
strictly below 1, while only for (4) and (5) can $\nu$ exceed 1.
Models with Fano factors $\le 1$ cannot produce the FISH data
observed in~\cite{Jones2014} without introducing additional
assumptions and model complexity.
}
\label{fig:constit_cartoons}
\end{figure}

\subsubsection{Model 1 - Poisson promoter.}
This is the picture from Jones et.\ al.~\cite{Jones2014}, which
assumes that transcripts are produced as a Poisson process from a
single promoter state. This model insists that the ``true'' mRNA
distribution is Poisson, implying the Fano factor $\nu$ must be 1.
In~\cite{Jones2014}, the authors carefully attribute deviations
from Fano = 1 to intensity variability in fluorescent spots, gene
copy number variation, and copy number fluctuations of the
transcription machinery, e.g., RNAP itself.
In this picture, the master equation makes no appearance,
and all the corrections to Poisson behavior are derived
as additive corrections to the Fano factor.
For disproving the ``universal noise curve'' from So et
al~\cite{So2011}, this picture was excellent. It is appealing in
its simplicity, with only two parameters, the initiation rate $r$
and degradation rate $\gamma$. Since $\gamma$ is independently
known from other experiments, and the mean mRNA copy number is
$r/\gamma$, $r$ is easily inferred from data.
In other words, the model is not excessively complex for the data at hand.
But for many interesting questions, for instance in the recent
work~\mmnote{cite Manuel's preprint once posted},
knowledge of means and variances alone is insufficient, and a
description of the full distribution of molecular counts is necessary.
For this we need a( slightly) more complex model than model 1
that would allow us to incorporate the non-Poissonian features of
constitutive promoters directly into a master equation formulation.

\subsubsection{Model 2 - Two-state promoter, RNAP bound or unbound.}
This model was considered in, e.g.,~\cite{Phillips2015a} and ~\cite{Phillips2019}.
Here transcription initiation proceeds from the bound to the unbound state,
reflecting the microscopic reality that an RNAP that has begun to elongate
a transcript is no longer available at the start site to begin another.
The problem with this picture is that the Fano factor is
\begin{align}
    \nu = 1 -
        \frac{r\rate{k}{P}{+}}
            {\left(\rate{k}{P}{+} + \rate{k}{P}{-} + r\right)
             \left(\gamma + \rate{k}{P}{+} + \rate{k}{P}{-} + r\right)},
\end{align}
which is always $<1$.
To make contact with the experimental reality of $\nu>1$,
we will have to do, at a minimum,
the same corrections to Poisson behavior as in model 1 above.
So while this model adds an appealing element of microscopic
reality, we are forced to reject it as the additional complexity
is unable to capture the phenomenology of interest.
Obviously the promoter state does in fact proceed through cycles
of RNAP binding, initiating, and elongating, but it seems that
the super-Poissonian noise in mRNA copy number we want to
model must be governed by other features of the system.

\subsubsection{Model 3 - Three-state promoter, multistep
transcription initiation and escape.}
How might we remedy the deficits of model 2?
It is known~\cite{DeHaseth1998} that once RNAP initially binds
the promoter region, a multitude of distinct steps occur
sequentially before RNAP finally escapes into the elongation
phase. Perhaps adding some of this mechanistic detail might
rescue model 2? The next simplest refinement of model 2 could
consider open complex formation and promoter escape as separate
steps rather than as a single effective step. In other words, we
construct model 3 by adding a single extra state to model 2, and
we will label the two RNAP-bound states as the closed and open
complexes, despite the true biochemical details certainly being
more complex. The authors of~\cite{Mitarai2015}, for instance,
considered this model, although they added an additional
repressor bound state and did not explicitly consider the limit
with no repressor that we analyze here. Again, our goal here is
not a complete accounting of all the relevant biochemical detail;
this is an exploratory search for the important features our
model needs to include.

Unfortunately, as the authors of~\cite{Mitarai2015} hint, this
model too has Fano factor $\nu<1$. This can be seen by starting
with their Eq.~A1 for the Fano factor of the analogous model with
repressor and taking the limit as repressor concentration goes to
zero. After substantial algebra, the result is
\begin{align}
\nu = 1 - \frac{r k_O k_P^+}{\mathcal{Z}}
\frac{k_P^+ + k_P^- + k_O + \gamma}
        {\mathcal{Z} + \gamma(k_P^+ + k_P^- + k_O + \gamma) + \gamma^2},
\end{align}
where we defined $\mathcal{Z} = r(k_O + k_P^-) + k_P^+(k_O + r)$
for notational tidiness. This is necessarily less than 1 for
arbitrary rate constants.

In fact, we suspect \textit{any} model in which transcription
proceeds through a multistep cycle must necessarily have $\nu<1$.
The intuitive argument compares the waiting time distribution to
traverse the cycle with the waiting time for a Poisson promoter
(model 1) with the same mean time. The latter is simply an
exponential distribution. The former is a convolution of multiple
exponentials, and intuitively should be more peaked with a
smaller fractional width than an exponential with the same mean.\footnote{
This can be made more precise with a result
from~\cite{Stewart2007}, who showed that the convolution of
multiple gamma distributions (of which the exponential
distribution is a special case) is to a very good approximation
also gamma distributed. Using their Eq.~2 for the distribution of
the convolution, with shape parameters set to 1 to
give exponential distributions, the total waiting time
distribution has a ratio of variance to squared mean 
$\sigma^2/\mu^2 = \sum_i k_i^2/\left(\sum_i k_i\right)^2$,
where the $k_i$ are the rates of the individual steps. Clearly
this is less than 1 and therefore the total waiting time
distribution is narrower than the corresponding exponential.} A
less disperse waiting time distribution means transcription
initations are more uniformly distributed in time relative to a
Poisson process. Hence the distribution of mRNA over a population
of cells should be less variable compared to Poisson, giving
$\nu<1$.\footnote{
This last step, while intuitive, can be argued by analogy to
photon statistics where antibunching gives rise to sub-Poissonian
noise~\cite{Paul1982, Zou1990}. Although loopholes exist, we do
not expect they apply for our problem. Nevertheless we refrain
from elevating this cycle/sub-Poissonian equivalence to a ``theorem.''
\mmnote{Antibunching is the ``obvious'' analogy for me but it'd
be totally out of left field for most readers, any suggestions on
a more comprehensible reference??}
}

Regardless of the merits of this model in describing the noise
properties of constitutive transcription initation, it does not
capture the dominant source of noise we want to include in our
phenomenological model, so we must discard these details and
search elsewhere.

\subsubsection{Model 4 - Two-state promoter,
``active'' and ``inactive'' states.}
Inspired by~\cite{Razo-Mejia2020}, we revisit an analog of model
2, but the interpretation of the two states is changed. Rather
than explicitly viewing them as RNAP bound and unbound, we view
them as ``active'' and ``inactive,'' which are able and unable to
initiate transcripts, respectively. We are noncommittal as to the
microscopic details of these states.

One interpretation~\cite{Chong2014, Sevier2016} for the active
and inactive states is that it represents the promoter's
supercoiling state: transitions to the inactive state are caused
by accumulation of positive supercoiling, which inhibits
transcription, and transitions back to ``active'' are caused by
gyrase or other topoisomerases relieving the supercoiling. This
is an interesting possibility because it would mean the timescale
for promoter state transitions is driven by topoisomerase
kinetics, not by RNAP kinetics. From in vitro measurments, the
former are suggested to be of order minutes~\cite{Chong2014}.
Contrast this with model 2, where the state transitions are
assumed to be governed by RNAP, which, assuming a copy number per
cell of order $10^3$, has a diffusion-limited association rate
$k_{on} \sim 10^2~\text{s}^{-1}$ to a target promoter. Combined
with known $K_D$'s of order $\mu$M, this gives an RNAP
dissociation rate $k_{off}$ of order $10^2$. As we will show
below, however, there are some lingering puzzles with
interpreting this supercoiling interpretation, so we leave it as
a speculation and refrain from assigning definite physical
meaning to the two states in this model.

Intuitively one might expect that, since transcripts are produced
as a Poisson process only when the promoter is in one of the two
states in this model, transcription initiations should now be
``bunched,'' in constrast to the ``anti-bunching'' of models 2
and 3 above. One might further guess that this bunching would
lead to super-Poissonian noise in the mRNA distribution over a
population of cells. An honest calculation of the Fano factor produces
\begin{align}
\nu &= 1 + \frac{r k^-}{(k^+ + k^- + \gamma)(k^+ + k^-)},
\end{align}
which is strictly greater than 1, verifying the above intuition.
Note we have dropped the $P$ label on the promoter switching rates to
emphasize that these very likely do not represent kinetics of RNAP itself.
This calculation can also be sidestepped by noting that the model
is mathematically equivalent to the simple repression repression model
from~\cite{Jones2014}, with states and rates relabeled and reinterpreted.

How does this model compare to model 1 above?
In model 1, all non-Poisson features of the mRNA
distribution were handled as extrinsic corrections.
By contrast, here the 3 parameter model is used to fit the full
mRNA distribution as measured in mRNA FISH experiments.
In essense, all variability in the mRNA distribution is regarded
as ``intrinsic,'' arising either from stochastic initiation or
from switching between the two coarse-grained promoter states.
The advantage of this approach is that it fits neatly into the
master equation picture, and the parameters thus inferred can be used as
input for more complicated models with regulation by transcription factors.

While this seems promising, there is a major drawback for our purposes
which was already uncovered by the authors of~\cite{Razo-Mejia2020}:
the statistical inference problem is nonidentifiable,
in the sense described in Section 4.3 of~\cite{Gelman2013},
meaning it is impossible to infer the
parameters $r$ and $k^-$ from the FISH data of~\cite{Jones2014}
(as shown in Fig.~S2 of~\cite{Razo-Mejia2020}).
Rather, only the ratio $r/k^-$ could be inferred. In that work,
the problem was worked around with an informative prior on the
ratio $k^-/k^+$. That approach is unlikely to work here, as,
recall, our entire goal in modeling constitutive expression is to
use it as the basis for a yet more complicated model, when we add
on repression. But adding more complexity to a model that is
already poorly identified is a fool's errand,
so we will explore one more potential model.

\subsubsection{Model 5 - One-state promoter with explicit bursts.}
This model is inspired by the failure mode of model 4.
The key observation above was that, as found
in~\cite{Razo-Mejia2020}, only two parameters, $k^+$ and the
ratio $r/k^-$, could be directly inferred from the FISH data
from~\cite{Jones2014}.
So let us take this seriously and imagine a model where these are
the only two model parameters. What would this model look like?

To develop some intuition, consider model 4 in the limit
$k^+ \ll k^- \lesssim r$, which is roughly satisfied by the
parameters inferred in~\cite{Razo-Mejia2020}.
In this limit, the system spends the majority of its time in the inactive state, occasionally becoming active and making a burst of transcripts.
This should call to mind the well-known phenomenon of transcriptional bursting, as reported in, e.g.,~\cite{Golding2005,Chong2014,Sevier2016}\mmnote{should probably add some more cites here}.
Let us make this correspondence more precise.
The mean dwell time in the active state is $1/k^-$.
While in this state, transcripts are produced at a rate $r$ per
unit time. So on average, $r/k^-$ transcripts are produced before
the system switches to the inactive state. Once in the inactive
state, the system dwells there for an average time $1/k^+$ before
returning to the active state and repeating the process. $r/k^-$
resembles an average burst size, and $1/k^+$ resembles the time
interval between burst events. More precisely, $1/k^+$ is the
mean time between the end of one burst and the start of the next,
whereas $1/k^+ + 1/k^-$ would be the mean interval between the
start of two successive burst events, but in the limit $k^+ \ll
k^-$, $1/k^+ + 1/k^- \approx 1/k^+$. Note that this limit ensures
that the waiting time between bursts is approximately
exponentially distributed, with mean set by the only timescale
left in the problem,
$1/k^+$.\footnote{
If instead it were the case that $k^+ \sim k^-$, then the waiting time
$1/k^+ + 1/k^-$ would have a peaked distribution, but this does
not appear to be the case for any of datasets
from~\cite{Jones2014}.}

Let us now verify this intuition with a precise derivation
to check that $r/k^-$ is in fact the mean burst size
and to obtain the full burst size distribution.
Consider first a constant, known dwell time $T$ in the active state.
Transcripts are produced at a rate $r$ per unit time, so the
number of transcripts $n$ produced during $T$ fits exactly
the ``story'' for the Poisson distribution, i.e.,
\begin{equation}
    P(n\mid T) = \frac{(rT)^n}{n!} \exp(-rT).
\end{equation}
Since the dwell time $T$ is unobservable, we actually want $P(n)$,
the dwell time distribution with no conditioning on $T$.
Basic rules of probability theory tell us we can write $P(n)$
in terms of $P(n\mid T)$ as
\begin{equation}
    P(n) =\int_0^\infty P(n\mid T) P(T) dT.
\end{equation}
But we know the dwell time distribution $P(T)$,
which is exponentially distributed according to
\begin{equation}
    P(T) = k^- \exp(-T k^-),
\end{equation}
so $P(n)$ can be written as
\begin{equation}
    P(n) = k^- \frac{r^n}{n!}
            \int_0^\infty T^n\exp[-(r + k^-)T]\,dT.
\end{equation}
A standard integral table shows
$\int_0^\infty x^n e^{-ax}\,dx = n!/a^{n+1}$, so
\begin{equation}
    P(n) = \frac{k^- r^n}{(k^- + r)^{n+1}}
        = \frac{k^-}{k^- + r}
            \left(\frac{r}{k^- + r}\right)^n
        = \frac{k^-}{k^- + r}
            \left(1 - \frac{k^-}{k^- + r}\right)^n,
\end{equation}
which is exactly the geometric distribution with standard parameter
$\theta\equiv k^-/(k^- + r)$ and domain
$n \in \{0, 1, 2, \dots\}$
(this is one of two common conventions for the geometric distribution).
The mean of the geometric distribution, with this convention, is
\begin{align}
\langle n\rangle = \frac{1 - \theta}{\theta}
        = \left(1 - \frac{k^-}{k^- + r}\right)
                    \frac{k^- + r}{k^-}
        = \frac{r}{k^-},
\end{align}
exactly as we guessed intuitively above.

So in taking the limit $r,k^-\rightarrow\infty$, $r/k^-\equiv b$,
we obtain a model which effectively has only a single promoter state,
which initiates bursts at rate $k^+$
(transitions to the active state, in the model 4 picture).
The master equation for mRNA copy number $m$ takes the form
\begin{align}
\begin{split}
\deriv{t}{p(m,t)} = & (m+1)\gamma p(m+1,t) - m\gamma p(m,t) \\
        &+ \sum_{j=0}^{m-1} k^+ p(j,t) Geom(m-j;b)
         - \sum_{j=m+1}^\infty k^+ p(m,t) Geom(j-m;b),
\end{split}
\end{align}
where $Geom(n;b)$ is the geometric distribution with mean~$b$, i.e.,
$Geom(n;b) = \frac{1}{1+b}\left(\frac{b}{1+b}\right)^n$
(with domain over nonnegative integers as above).
The first two terms are the usual mRNA degradation terms.
The third term enumerates all ways the system can produce
a burst of transcripts and arrive at copy number $m$,
given that it had copy number $j$ before the burst.
The fourth term allows the system to start with copy number $m$,
then produce a burst and end with copy number $j$.
In fact this last sum has trivial $j$ dependence and
simply enforces normalization of the geometric distribution.
Carrying it out we have
\begin{equation}
\begin{split}
\deriv{t}{p(m,t)} = & (m+1)\gamma p(m+1,t) - m\gamma p(m,t) \\
        &+ \sum_{j=0}^{m-1} k^+ p(j,t) Geom(m-j;b)
            - k^+ p(m,t),
\end{split}
\end{equation}
This improves on model 4 in that now the parameters are easily inferred,
as we will see later, and have clean interpretations.
The non-Poissonian features are attributed to the emprically
well-established phenomenological picture of bursty transcription.

The big approximation in going from model 4 to 5 is that a burst
is produced instantaneously rather than over a finite time.
If the true burst duration is not short compared to transcription factor
kinetic timescales, this could be a problem in that mean burst size
in the presense and absence of repressors could change,
rendering parameter inferences from the constitutive case inappropriate.
Let us make some simple estimates of this.

Consider the time delay between the first and final RNAPs
in a burst initiating transcription
(\textit{not} the time to complete transcripts,
which potentially could be much longer.)
If this timescale is short compared to the typical
search timescale of transcription factors, then all is well.
The estimates from deHaseth et.\ al.~\cite{DeHaseth1998}
put RNAP's diffusion-limited on rate around
$\sim\text{few}\times10^{-2}~\text{nM}^{-1}~\text{s}^{-1}$
and polymerase loading as high as $1~\text{s}^{-1}$.
Then for reasonable burst sizes of $<10$, it is reasonable to guess that
bursts might finish initiating on a timescale of tens of seconds or less
(with another 30-60 sec to finish elongation, but that does not matter here).
A transcription factor with typical copy number of order 10 (or less)
would have a diffusion-limited association rate of order
$(10~\text{sec})^{-1}$.
Higher copy number TFs tend to have many binding sites over the genome,
which should serve to pull them out of circulation and keep their
effective association rates from rising too large.
Therefore, there is \textit{perhaps} a timescale separation
possible between transcription factor association rates and burst
durations, but this assumption could very well break down, so we
will have to keep it in mind when we infer repressor rates from
the Jones et.\ al.\ FISH data later.

In reflecting on these 5 models, the reader may feel that
exploring a multitude of potential models just to return to a
very minimal phenomenological model of bursty transcription may
seem highly pedantic. But the purpose of the exercise was to
examine a host of models from the literature and understand why
they are insufficient, one way or another, for our purposes.
Along the way we have learned that the detailed kinetics of RNAP
binding and initiating transcription are probably irrelevant for
setting the population distribution of mRNA.
The timescales are simply too fast, and as we will see later
in~\fig{fig:constit_post}, the noise seems to be governed by
slower timescales. Perhaps in hindsight this is not surprising:
intuitively, the degradation rate $\gamma$ sets the fundamental
timescale for mRNA dynamics, and any other processes that
substantially modulate the mRNA distribution should not differ
from $\gamma$ by orders of magnitude.

\subsection{Parameter inference for constitutive promoters}
Having established that a one-state bursty model achieves a
Goldilocks level of complexity, we test it more thoroughly on all
the data from constitutive promoters from~\cite{Jones2014}.
\fig{fig:constit_post} shows the results.
\begin{figure}%[h!]
\centering
\includegraphics[width=0.9\textwidth]{../figures/fig2/fig2.pdf}
\caption{\textbf{Constitutive promoter model comparison.}
    (A) ???
    (B) shows the ECDF of the observed population distribution
    of mRNA transcripts under the control of a constitutive lacUV5 promoter.
    Fits of model (1), Poisson, and model (5), negative binomial, are shown.
    \mmnote{Would like to add posterior predictive intervals,
    to give sense of robustness of model.}
    (C) 95\% highest posterior density regions for burst rate $k_i$ and
    mean burst size $b$ for 18 promoters from Brewster 2012. Legend is
    same as (d).
    \mmnote{shared y axis??}
    (D) Burst rate $k_i$ plotted vs.\ binding energy from energy
    matrices from Brewster 2012.
    \mmnote{Need to add fit line still. Also visibility of color palette is very bad, adjust.
    There are 18 data points, maybe 6 colors and 3 glyphs/linestyles
    cycled through? or 9 and 2?}
    }
\label{fig:constit_post}
\end{figure}
\mmnote{Discuss puzzling comparison w/ Chong2014: if supercoiling is the thing, why are my burst sizes all the same but burst rates vary? And why is the duty cycle of my promoter so low, ie., bursts so short? COmpare their fig 7E; their $\beta/\alpha$ is my $k^+/k^-$. They have one or two genes with very small $\beta/\alpha$, does the \textit{galK} locus just happen to be that, or is there a deeper disagreement? Hard to say w/o more data.}

\subsection{Transcription factor kinetics can be inferred from FISH measurements}
Figure~3 presents inferred transcription factor rates, compares
them to single-molecule measurements, and compares their ratios
to gold-standard binding energies.
\begin{figure}%[h!]
\centering
\includegraphics[width=0.9\textwidth]{../figures/fig3/fig3.ai}
\caption{\textbf{Simple repression model comparison.}
(A) depicts the cartoon of simple repression for which we infer parameters.
(B) shows 50\% and 95\% contours of several 2D slices of the 9D posterior
distribution, from fitting one unbinding rate for each operator (O1, O2, O3)
and one binding rate for each aTc concentration (corresponding to an
unknown mean repressor copy number).
(C) compares ratios of our inferred unbinding rates with operator
binding energy differences measured in Garcia \& Phillips 2011 (triangles)
and Razo-Mejia et.\ al.\ 2018 (squares).
(D) compares our inferred unbinding rates with single-molecule measurements
of the same from Hammar et.\ at.\ 2014 \mmnote{Johan Elf's group}.
Values are of similar order of magnitude,
but a precise quantitative comparison unfortunately depends sensitively
on the assumed mRNA lifetime, which was not measured.
    }
\label{fig3:kR_inferences}
\end{figure}

\begin{figure}%[h!]
\centering
\includegraphics[width=0.9\textwidth]{../figures/figSIxx/ppc_many_pooled.pdf}
\caption{\textbf{Posterior predictive checks.}
(A) duplicates the posterior from~\fig{fig3:kR_inferences}B.
(B), (C), and (D) show samples from the posterior predictive distribution
for each of the datasets used in the inference.
Samples are sorted by operator and plotted separately simply for visual clarity.
The unrepressed promoter, UV5, is shown with each as a reference point.
\mmnote{
Obviously the PPC is not perfect,
but considering the relative simplicity of the model, I'm pleasantly surprised
how well it worked and that the model was even identifiable at all.
Interestingly, and perhaps not surprisingly, only 3 of the 9 datasets
were identifiable if fit in isolation: otherwise,
it was only by making assumptions that certain rates are equal
across datasets was identifiability achieved.
}
    }
\label{fig4:ppc}
\end{figure}

\section{Discussion and future work}
\mmnote{
Do all my approximations work simply because galK happens to have
a low duty cycle of supercoiling, $\beta/\alpha$ in Chong2014
picture? A potentially interesting test: put in the dozen or so
Hernan constructs at some other locus, preferably one of the ones
Chong identified as having a large duty cycle (large $\beta/\alpha$),
i.e., the opposite limit of galK. Then just measure fold-changes.
You don't even need to do FISH, although that would be even
better. If their model is right, $\rho$ should be approximately
set by the duty cycle of supercoiling, NOT by RNAP kinetics.
\textit{This is a NICE prediction for future work.} \textit{cspE}
is claimed nonessential, prediction is you drop HG reporter
constructs in there and the inferred binding energies of all lacI
operators shift the same amount, by about $\ln(3)\sim 1kT$. Not
huge, but detectable, although might be confounding effects from
moving to a new locus. With FISH measurements, $k^+$ and $k^-$ in
Fig 2, model 4 should now be separately inferrable if Chong2014
measurements of $\beta/\alpha$ are correct. This would require an
obnoxious amount of cloning, but once you did that, the
measurements would be same old stuff that RP lab does.}

\appendix

\section{Derivations of constitutive promoter models}
\subsection{Model 2}
\mmnote{Obtain Fano factor from CME.}
\subsection{Model 3}
\mmnote{Obtain Fano factor by taking limit from Mitarai et al's expression.}
\subsection{Model 4}
\mmnote{Obtain Fano factor by relabeling cartoon from Jones2014.}

\section{Generating function solution for bursty promoters}

\subsection{Constitutive promoter with bursts}

\subsubsection{From master equation to generating function}

We would like to derive the full probability distribution of
mRNA copy number per cell for a model combining simple repression
with a promoter featuring bursty transcription initiation.
Before tackling mRNA and repression together, let us
just consider the bursty consititutive promoter,
model 4 in~\fig{fig:constit_post}
\mmnote{replicating Charlotte's notes; she says it's worked out
in~\cite{Paulsson2000}, but I don't see it, at least not in notation I can
comprehend. Need to find a cite for this,
or maybe just cite Charlotte, personal comm, since that's where I actually got it\dots}.
The master equation of interest is
\begin{align}
\deriv{t}p(m,t) = (m+1)\gamma p(m+1,t) - m\gamma p(m,t) - r p(m,t)
        + r \sum_{m^\prime=0}^m G_{m-m^\prime}(\theta) p(m^\prime,t),
\label{eq:1state_unreg_003}
\end{align}
where $G_{k}(\theta)$ is the geometric distribution defined as
\begin{align}
G_{k}(\theta) = \theta(1 - \theta)^k, \, k\in\{0,1,2,\dots\}.
\end{align}
With this convention, the mean burst size $b = (1-\theta)/\theta$.
$\gamma$ and $r$ are mRNA degradation rates and transcription burst
initiation rates, resp. The last term represents all ways the system could
end up with $m$ mRNAs, having started the burst with $m^\prime$. Define
$\lambda = r/\gamma$ and nondimensionalize time by $\gamma$, giving
\begin{align}
\deriv{t}p(m,t) = (m+1)p(m+1,t) - m p(m,t) - \lambda p(m,t)
        + \lambda \sum_{m^\prime=0}^m G_{m-m^\prime}(\theta) p(m^\prime,t),
\end{align}
The probability generating function is defined as
\begin{align}
F(z,t) = \sum_{m=0}^\infty z^m p(m,t).
\end{align}
Multiply both sides of the CME by $z^m$ and sum over all $m$ to get
\begin{align}
\pderiv[F]{t} = \sum_{m=0}^\infty z^m
\left(
(m+1)p(m+1,t) - m p(m,t) - \lambda p(m,t)
+ \lambda \sum_{m^\prime=0}^m G_{m-m^\prime}(\theta) p(m^\prime,t)
\right).
\end{align}
The first two terms can be rewritten as derivatives of the
generating function, i.e.,
\begin{align}
\sum_{m=0}^\infty z^m (m+1)p(m+1,t)
=
\pderiv{z} \sum_{m=0}^\infty z^{m+1} p(m+1,t)
=
\pderiv[F]{z}
\end{align}
and
\begin{align}
\sum_{m=0}^\infty z^m mp(m,t)
=
z\pderiv{z} \sum_{m=0}^\infty z^m p(m,t)
=
z\pderiv[F]{z}.
\end{align}
The final term is the most trouble. The trick is to reverse
the default order of the sums, as in
\begin{align}
&\lambda \sum_{m=0}^\infty \sum_{m^\prime=0}^m
        z^m \theta(1 - \theta)^{m-m^\prime} p(m^\prime,t)
\\=
&\lambda\theta \sum_{m^\prime=0}^\infty z^{m^\prime} p(m^\prime,t)
        \sum_{m=m^\prime}^\infty
        z^{m-m^\prime} (1 - \theta)^{m-m^\prime}
\\=
&\frac{\lambda\theta F}{1 - (1 - \theta)z}.
\end{align}
This works because after reordering the sums, the sum on $m$ is just
a geometric series. Its result is independent of $m^\prime$, so the sum on
$m^\prime$ reduces to the definition of the generating function.
Putting these results together, the PDE for the generation function is
\begin{align}
\pderiv[F]{t} = \pderiv[F]{z} - z\pderiv[F]{z} - \lambda F
        + \frac{\lambda\theta F}{1-z(1-\theta)}.
\end{align}
Changing variables to $\xi=1-\theta$ and simplifying gives
\begin{align}
\pderiv[F]{t} + (z - 1) \pderiv[F]{z} = \frac{(z-1)\xi}{1-z\xi}\lambda F.
\label{eq:1state_unreg_015}
\end{align}
\subsubsection{Stead-state}
At steady-state, the PDE reduces to the ODE
\begin{align}
\deriv[F]{z} = \frac{\xi}{1-z\xi}\lambda F,
\end{align}
which we can integrate as
\begin{align}
\int \frac{dF}{F} = \int \frac{\lambda\xi dz}{1-\xi z}.
\end{align}
The initial conditions for generating functions can be subtle and confusing.
The key fact follows from the definition
$F(z,t) = \sum_m z^m p(m,t)$,
normalization requires that
$F(z=1^-,t) = \sum_m p(m,t) = 1$.\footnote{
Sometimes the generating function may be undefined \textit{at} $z=1$ but the
limit still holds. Also many authors change variables from $z$ to other
things, so one must keep track of how the normalization condition transforms.
}
Doing the integrals (and producing constant $c$) gives
\begin{align}
\ln F &= -\lambda \ln(1-\xi z) + c
\\
F &= \frac{c}{(1-\xi z)^\lambda}.
\end{align}
Only one choice for $c$ can satisfy initial conditions, producing
\begin{align}
F(z) = \left(\frac{1-\xi}{1-\xi z}\right)^\lambda
        = \left(\frac{\theta}{1 - z(1-\theta)}\right)^\lambda,
\end{align}
which is exactly the negative binomial's generating function, as expected.

\subsection{Adding repression}
\subsubsection{Deriving the generating function for mRNA distribution}

Let us move from a one-state promoter to a two-state promoter, where one state
has repressor bound and the other produces transcriptional bursts as above.
A schematic of this model is shown in~\fig{fig3:kR_inferences}.
Although now we have an equation for each promoter state, otherwise
the master equation reads similarly to the one-state case, except with
additional terms corresponding to transitions between promoter states, namely
\begin{align}
\deriv{t}p_R(m,t) =& k_R^+ p_A(m,t) - k_R^- p_R(m,t)
        + (m+1)\gamma p_R(m+1,t) - m\gamma p_R(m,t)
\\
\begin{split}
\deriv{t}p_A(m,t) =& - k_R^+ p_A(m,t) + k_R^- p_R(m,t)
        + (m+1)\gamma p_A(m+1,t) - m\gamma p_A(m,t) 
\\
&- k_i p_A(m,t) + k_i \sum_{m^\prime=0}^m \theta(1-\theta)^{m-m^\prime} p_A(m^\prime,t),
\end{split}
\end{align}
where $p_R(m,t)$ is the probability of the system having $m$ mRNA copies
and having repressor bound to the promoter at time $t$, and $p_A$ is an
analogous probability to find the promoter without repressor bound.
$k_R+$ and $k_R^-$ are, respectively, the rates at which repressors
bind and unbind to and from the promoter, and
$\gamma$ is the mRNA degradation rate.
$k_i$ is the rate at which bursts initiate, and as before,
the geometric distribution of burst sizes has mean $b=(1-\theta)/\theta$.\footnote{
$\theta$ can be viewed as a Bernoulli trial probability: after each transcript
in a burst is produced, $\theta$ is the probability that the burst
terminates and $(1-\theta)$ is the probability that the burst continues.
}

Interestingly, it turns out that this problem maps exactly onto the
three-stage promoter model considered by
Shahrezaei and Swain in~\cite{Shahrezaei2008}, with relabelings.
Their approximate solution for protein distributions amounts to
the same approximation we make here in regarding the duration
of mRNA synthesis bursts as instantaneous, so their solution
for protein distributions also solves our problem of mRNA distributions.
Let us examine the analogy more closely.
They consider a two-state promoter, as we do here, but they model
mRNA as being produced one at a time and degraded, with rates
$v_0$ and $d_0$.
Then they model translation as occuring with rate $v_1$,
and protein degradation with rate $d_1$.
Now consider the limit where $v_1, d_0\rightarrow\infty$ with
their ratio $v_1/d_0$ held constant.
$v_1/d_0$ resembles the average burst size of translation from a single
mRNA: these are the rates of two Poisson processes that compete over a
transcript, which matches the story of geometrically distributed burst sizes.
So after taking this limit, on timescales slow compared to $v_1$ and $d_0$,
it appears that transcription events fire at rate $v_0$ and produce a
geometrically distributed burst of translation of mean size $v_1/d_0$,
which intuitively matches the story we have told above for mRNA
with variables relabeled.

To verify this intuitively conjectured mapping between our problem and
the solution in~\cite{Shahrezaei2008}, we continue with a careful
solution for the mRNA distribution using probability generating functions,
following the ideas sketched in~\cite{Shahrezaei2008}.
It is natural to nondimensionalize rates in the problem by $\gamma$,
or equivalently, this amounts to measuring time in units of $\gamma^{-1}$.
We are also only interested in steady state, so we set the time
derivatives to zero, giving
\begin{align}
0 =& k_R^+ p_A(m) - k_R^- p_R(m) + (m+1) p_R(m+1) - m p_R(m)
\\
\begin{split}
0 =& - k_R^+ p_A(m) + k_R^- p_R(m) + (m+1) p_A(m+1) - m p_A(m) 
\\
&- k_i p_A(m) + k_i \sum_{m^\prime=0}^m \theta(1-\theta)^{m-m^\prime} p_A(m^\prime),
\end{split}
\end{align}
        
The probability generating function is defined as before in the
constitutive case, except now we must introduce a generating function
for each promoter state,
\begin{align}
f_A(z) = \sum_{m=0}^\infty z^m p_A(m),
\;
f_R(z) = \sum_{m=0}^\infty z^m p_R(m).
\end{align}
Our real objective is the generating function $f(z)$ that generates
the mRNA distribution $p(m)$, independent of what state the promoter is in.
But since $p(m) = p_A(m) + p_R(m)$, it follows too that $f(z) = f_A(z) + f_R(z)$.

So as before we multiply both equations by $z^m$ and sum over all $m$.
Each individual term transforms exactly as did an analogous term in
the constitutive case, so the coupled ODEs for the generating functions read
\begin{align}
0 =& k_R^+ f_A(z) - k_R^- f_R(z) + \pderiv{z} f_R(z) - z \pderiv{z} f_R(z)
\\
\begin{split}
0 =&  - k_R^+ f_A(z) + k_R^- f_R(z) + \pderiv{z} f_A(z) - z \pderiv{z} f_A(z)
\\
&- k_i f_A(z) + k_i \frac{\theta}{1-z(1-\theta)} f_A(z),
\end{split}
\end{align}
and after changing variables $\xi = 1 - \theta$ as before
and rearranging, we have
\begin{align}
0 &= k_R^+ f_A(z) - k_R^- f_R(z) + (1-z) \pderiv{z} f_R(z)
\\
0 &=  - k_R^+ f_A(z) + k_R^- f_R(z) + (1 - z) \pderiv{z} f_A(z)
+ k_i \frac{(z-1)\xi}{1-z\xi} f_A(z),
\end{align}
We can transform this problem from two coupled first-order ODEs to a
single second-order ODE by solving for $f_A$ in the first and plugging
into the second, giving
\begin{align}
\begin{split}
0 = (1&-z) \pderiv[f_R]{z}
+ \frac{1-z}{k_R^+}
        \left(k_R^- \pderiv[f_R]{z} + \pderiv[f_R]{z} +(z-1) \psecderiv[f_R]{z}\right)
\\
&+ \frac{k_i}{k_R^+} \frac{(z-1)\xi}{1-z\xi}
        \left(k_R^- f_R + (z-1) \pderiv[f_R]{z}\right),
\end{split}
\end{align}
where, to reduce notational clutter, we have dropped the explicit $z$
dependence of $f_A$ and $f_R$. Simplifying we have
\begin{align}
0 = \psecderiv[f_R]{z}
        - \left(\frac{k_i\xi}{1-z\xi}
                + \frac{1 + k_R^- + k_R^+}{1-z}
        \right)\pderiv[f_R]{z}
        + \frac{k_i k_R^- \xi}{(1-z\xi)(1-z)}f_R.
\end{align}
This can be recognized as the hypergeometric differential equation,
with singularities at $z=1$, $z=\xi^{-1}$, and $z=\infty$. The latter
can be verified by a change of variables from $z$ to $x=1/z$,
being careful with the chain rule, and noting that $z=\infty$ is a
singular point if and only if $x=1/z=0$ is a singular point.

The standard form of the hypergeometric differential equation has its
singularities at 0, 1, and $\infty$, so to take advantage of the
standard form solutions to this ODE, we first need to transform
variables to put it into a standard form.
However, this is subtle. While any such transformation should work in
principle, the solutions are expressed most simply in the neighborhood
of $z=0$, but the normalization condition that we need to enforce
corresponds to $z=1$. The easiest path, therefore, is to find a change
of variables that maps
1 to 0, $\infty$ to $\infty$, and $\xi^{-1}$ to 1.
This is most intuitively done in two steps.

First map the $z=1$ singularity to 0 by the change of variables $v=z-1$, giving
\begin{align}
0 = \psecderiv[f_R]{v}
        + \left(\frac{k_i\xi}{(1+v)\xi - 1}
                + \frac{1 + k_R^- + k_R^+}{v}
        \right)\pderiv[f_R]{v}
        + \frac{k_i k_R^- \xi}{((1+v)\xi - 1)v}f_R.
\end{align}
Now two singularities are at $v=0$ and $v=\infty$.
The third is determined by $(1+v)\xi -1 = 0$, or $v=\xi^{-1} - 1$.
We want another variable change that maps this third singularity to 1
(without moving 0 or infinity). Changing variables again to
$w=\frac{v}{\xi^{-1} - 1} = \frac{\xi}{1-\xi} v$ fits the bill.
In other words, the combined change of variables
\begin{align}
w = \frac{\xi}{1-\xi} (z-1)
\end{align}
maps $z = \{1, \xi^{-1}, \infty\}$ to $w =\{0, 1, \infty\}$ as desired.
Plugging in, being mindful of the chain rule and noting
$(1 + v)\xi - 1 = (1 - \xi)(w - 1)$ gives
\begin{align}
0 = \left(\frac{\xi}{1-\xi}\right)^2 \psecderiv[f_R]{w}
+ \left(
        \frac{\xi k_i}{(1-\xi)(w-1)} + \frac{\xi(1 + k_R^- + k_R^+)}{(1-\xi)w}
\right) \frac{\xi}{1-\xi} \pderiv[f_R]{w}
+ \frac{k_i k_R^- \xi^2}{(1-\xi)^2 w(w-1)}f_R.
\end{align}
This is close to the standard form of the hypergeometric differential
equation, and some cancellation and rearrangement gives
\begin{align}
0 = w(w-1)\psecderiv[f_R]{w}
+ \left(k_i w + (1 + k_R^- + k_R^+)(w-1)\right) \pderiv[f_R]{w}
+ k_i k_R^- f_R.
\end{align}
and a little more algebra produces
\begin{align}
0 = w(1-w)\psecderiv[f_R]{w}
+ \left(1 + k_R^- + k_R^+
        - (1 + k_i + k_R^- + k_R^+)w
\right) \pderiv[f_R]{w}
- k_i k_R^- f_R,
\end{align}
which is the standard form. From this we can read off the solution
in terms of hypergeometric functions ${_2F_1}$ from
any standard source, e.g.~\cite{Abramowitz1964}, and identify the
conventional parameters in terms of our model parameters.
We want the general solution in the neighborhood of $w=0$ ($z=1$),
which for a homogeneous linear second order ODE must be a sum of two
linearly independent solutions.
More precisely,
\begin{align}
f_R(w) = C_1 {_2F_1}(\alpha, \beta, \gamma; w)
+ C_2 w^{1-\gamma}{_2F_1}(1+\alpha-\gamma, 1+\beta-\gamma, 2-\gamma; w)
\end{align}
with parameters determined by
\begin{align}
\begin{split}
\alpha\beta &= k_i k_R^-
\\
1+\alpha+\beta &= 1+k_i+k_R^-+k_R^+
\\
\gamma &= 1 + k_R^- + k_R^+
\end{split}
\end{align}
and constants $C_1$ and $C_2$ to be set by boundary conditions.
Solving for $\alpha$ and $\beta$, we find\footnote{
Note that $\alpha$ and $\beta$ are interchangeable in the definition of
${_2F_1}$ and differ only in the sign preceeding the radical.
}
\begin{align}
\begin{split}
\alpha &= \frac{1}{2}
\left(k_i+k_R^-+k_R^+ + \sqrt{(k_i+k_R^-+k_R^+)^2 - 4k_i k_R^-}\right)
\\
\beta &= \frac{1}{2}
\left(k_i+k_R^-+k_R^+ - \sqrt{(k_i+k_R^-+k_R^+)^2 - 4k_i k_R^-}\right)
\\
\gamma &= 1 + k_R^- + k_R^+.
\end{split}
\end{align}
Since the normalization condition requires that $f_R$ be finite at $w=0$,
we can immediately set $C_2=0$ to discard the second solution.
This is because all the rate constants are strictly positive,
so $\gamma>1$ and therefore $w^{1-\gamma}$ blows up as $w\rightarrow0$.
Now that we have $f_R$, we would like to find the generating function
for the mRNA distribution, $f(z) = f_A(z) + f_R(z)$.
We can recover $f_A$ from our solution for $f_R$, namely
\begin{align}
f_A(z) = \frac{1}{k_R^+}\left(k_R^- f_R(z) + (z-1) \pderiv[f_R]{z}\right)
\end{align}
or
\begin{align}
f_A(w) = \frac{1}{k_R^+}\left(k_R^- f_R(w) + w \pderiv[f_R]{w}\right),
\end{align}
where in the second line we transformed our original relation between
$f_R$ and $f_A$ to our new, more convenient, variable $w$.
Plugging our solution for $f_R(w) = C_1{_2F_1}(\alpha, \beta, \gamma; w)$
into $f_A$, we will require the differentiation rule for ${_2F_1}$,
which tells us
\begin{align}
\pderiv[f_R]{w} = C_1\frac{\alpha\beta}{\gamma}
                {_2F_1}(\alpha+1, \beta+1, \gamma+1; w),
\end{align}
from which it follows that
\begin{align}
f_A(w) = \frac{C_1}{k_R^+}
\left(
k_R^- {_2F_1}(\alpha, \beta, \gamma; w)
+ w\frac{\alpha\beta}{\gamma} {_2F_1}(\alpha+1, \beta+1, \gamma+1; w)
\right)
\end{align}
and therefore
\begin{align}
f(w) = C_1\left(1 + \frac{k_R^-}{k_R^+}\right)
        {_2F_1}(\alpha, \beta, \gamma; w)
+ w \frac{C_1}{k_R^+} \frac{\alpha\beta}{\gamma}
        {_2F_1}(\alpha+1, \beta+1, \gamma+1; w).
\end{align}
To proceed, we need one of the (many) useful identities known for
hypergeometric functions, in particular
\begin{align}
w\frac{\alpha\beta}{\gamma} {_2F_1}(\alpha+1, \beta+1, \gamma+1; w)
=
(\gamma-1)\left(
{_2F_1}(\alpha, \beta, \gamma-1; w) - {_2F_1}(\alpha, \beta, \gamma; w)
\right).
\end{align}
Substituting this for the second term in $f(w)$, we find
\begin{align}
f(w) = \frac{C_1}{k_R^+}
\left[
        \left(k_R^+ + k_R^-\right)
        {_2F_1}(\alpha, \beta, \gamma; w)
+ (\gamma-1)\left(
        {_2F_1}(\alpha, \beta, \gamma-1; w) - {_2F_1}(\alpha, \beta, \gamma; w)
        \right)
\right],
\end{align}
and since $\gamma-1 = k_R^+ + k_R^-$, the first and third terms cancel,
leaving only
\begin{align}
f(w) = C_1\frac{k_R^+ + k_R^-}{k_R^+} {_2F_1}(\alpha, \beta, \gamma-1; w).
\end{align}
Now we enforce normalization, demanding $f(w=0) = f(z=1) = 1$.
${_2F_1}(\alpha, \beta, \gamma-1; 0) = 1$, so we must have
$C_1 = k_R^+ / (k_R^+ + k_R^-)$ and consequently
\begin{align}
f(w) =  {_2F_1}(\alpha, \beta, k_R^+ + k_R^-; w).
\end{align}
Recalling that the mean burst size $b = (1-\theta)/\theta = \xi/(1-\xi)$
and $w = \frac{\xi}{1-\xi} (z-1) = b (z-1)$,
we can transform back to the original variable $z$ to find the tidy result
\begin{align}
f(z) =  {_2F_1}(\alpha, \beta, k_R^+ + k_R^-; b(z-1)),
\end{align}
with $\alpha$ and $\beta$ given above by
\begin{align}
\begin{split}
\alpha &= \frac{1}{2}
\left(k_i+k_R^-+k_R^+ + \sqrt{(k_i+k_R^-+k_R^+)^2 - 4k_i k_R^-}\right)
\\
\beta &= \frac{1}{2}
\left(k_i+k_R^-+k_R^+ - \sqrt{(k_i+k_R^-+k_R^+)^2 - 4k_i k_R^-}\right).
\end{split}
\end{align}
Finally we are in sight of the original goal. We can generate the
steady-state probability distribution of interest by
differentiating the generating function,
\begin{align}
p(m) = m! \left.\frac{\partial^m}{\partial z^m} f(z) \right|_{z=0},
\end{align}
which follows easily from its definition. Some contemplation reveals
that repeated application of the derivative rule used above will produce
products of the form $\alpha(\alpha+1)(\alpha+2)\cdots(\alpha+m-1)$ in
the expression for $p(m)$ and similarly for $\beta$ and $\gamma$. These
resemble ratios of factorials, but since $\alpha$, $\beta$, and $\gamma$
are not necessarily integer, we should express the ratios using gamma
functions instead. More precisely, one finds
\begin{align}
p(m) = \frac{
        \Gamma(\alpha + m)\Gamma(\beta + m)\Gamma(k_R^+ + k_R^-)
        }
        {
        \Gamma(\alpha)\Gamma(\beta)\Gamma(k_R^+ + k_R^- + m)
        }
\frac{b^m}{m!}{_2F_1}(\alpha+m, \beta+m, k_R^++k_R^-+m; -b)
\label{eq:p_m_bursty+rep}
\end{align}
which is finally the probability distribution we sought to derive.

\subsubsection{Moments}
We can verify the correctness of~\eq{eq:p_m_bursty+rep}
by comparison with Gillespie simulation.
We can also easily compute moments of the distribution from
the generating function, and check these against raw moments computed
directly from the master equation.

The $j$-th raw moment of the distribution can be computed from the
generating function from the formula
\begin{align}
\langle m^j \rangle
= \left. \left(z \frac{\partial}{\partial z}\right)^j f(z)\right|_{z=1}.
\end{align}
Note that \textit{probabilities} are generated by differentiating
and evaluating at $z=0$, while \textit{moments} are generated by
differentiating and evaluating at $z=1$. This also aligns with the
normalization constraint, which can be thought of as the zeroth raw moment.
        
The mean mRNA is given by
\begin{align}
\langle m \rangle = \left.z \pderiv[f]{z} \right|_{z=1}
= \frac{\alpha\beta b}{k_R^+ + k_R^-}
= k_i b\frac{k_R^-}{k_R^+ + k_R^-},
\end{align}
which is intuitive and appealingly simple:
the mean mRNA is just the mean mRNA in the absense of repression
($k_i b$, the burst rate time mean burst size)
times the fraction of time the repressor is bound, $k_R^-/(k_R^+ + k_R^-)$.

To compute the variance, let us first compute
\begin{align}
\begin{split}
\langle m^2\rangle
&= \left .z\pderiv{z}\left(z\pderiv[f]{z}\right) \right|_{z=1}
= \left. z\left(\pderiv[f]{z} + z\psecderiv[f]{z}\right)\right|_{z=1}
\\
&= \frac{\alpha\beta b}{k_R^+ + k_R^-}
        + \frac{\alpha(\alpha+1)\beta(\beta+1) b^2}
                {(k_R^+ + k_R^-)(k_R^+ + k_R^- + 1)}
\\
&= \frac{k_i b k_R^-}{k_R^+ + k_R^-}
        + \frac{k_i k_R^- b^2 (1 + k_i + k_R^+ + k_R^- + k_i k_R^-)}
                {(k_R^+ + k_R^-)(k_R^+ + k_R^- + 1)},
\end{split}
\end{align}
from which the variance is
\begin{align}
\begin{split}
var(m) = \langle m^2\rangle - \langle m\rangle^2
&= \frac{k_i b k_R^-}{k_R^+ + k_R^-}
\left(
1 + \frac{b(1 + k_i + k_R^+ + k_R^- + k_i k_R^-)} {k_R^+ + k_R^- + 1}
- \frac{k_i b k_R^-}{k_R^+ + k_R^-}
\right)
\\
&= k_i b\frac{k_R^-}{k_R^+ + k_R^-}
\left(
1 + b + k_i b\frac{1 + k_R^-} {k_R^+ + k_R^- + 1}
- \frac{k_i b k_R^-}{k_R^+ + k_R^-}
\right)
\\
&= k_i b\frac{k_R^-}{k_R^+ + k_R^-}
\left(
1 + b + k_i b\frac{k_R^+}{(k_R^+ + k_R^-)(k_R^+ + k_R^- + 1)}
\right).
\end{split}
\end{align}
The Fano factor is the quantity in parentheses. This can be interpreted as
the variability arising from the negative binomial distribution of the
unregulated promoter $(1+b)$ plus additional noise arising from repression.

\mmnote{Still to writeup: moment derivation direct from CME to compare}

\subsection{Numerical considerations and recursion formulas}
\subsubsection{Generalities}
We would like to carry out Bayesian parameter inference on FISH data
from~\cite{Jones2014}, using~\eq{eq:p_m_bursty+rep} as our
likelihood. This requires accurate (and preferably fast)
numerical evaluation of the hypergeometric function ${_2F_1}$,
which is a notoriously hard problem~\cite{Pearson2017, Gil2007},
and our particular needs here present an especial challenge as we show below.

The hypergeometric function is defined by its Taylor series as
\begin{align}
{_2F_1}(a,b,c;z) 
= \sum_{l=0}^\infty
\frac{\Gamma(a + l)\Gamma(b + l)\Gamma(c)}
        {\Gamma(a)\Gamma(b)\Gamma(c + l)}
\frac{z^l}{l!}
\end{align}
for $|z|<1$, and by analytic continuation elsewhere.
If $z\lesssim1/2$ and $\alpha$ and $\beta$ are not too large
(absolute value below 20 or 30),
then the series converges quickly and an accurate numerical representation is
easily computed by truncating the series after a reasonable number of terms.
Unfortunately, we need to evaluate ${_2F_1}$ over mRNA copy numbers fully out
to the tail of the distribution, which can easily reach 50, possibly 100.
From~\eq{eq:p_m_bursty+rep}, this means evaluating ${_2F_1}$
repeatedly for values of $a$, $b$, and $c$ spanning the full range
from $\mathcal{O}(1)$ to $\mathcal{O}(10^2)$,
even if $\alpha$, $\beta$, and $\gamma$
in~\eq{eq:p_m_bursty+rep} are small,
with the situation even worse if they are not small.
A naive numerical evaluation of the series definition will be
prone to overflow and, if any of $a,b,c<0$, then some successive terms in the
series have alternating signs which can lead to catastrophic cancellations.

One solution is to evaluate ${_2F_1}$ using arbitrary precision arithmetic
instead of floating point arithmetic,
e.g., using the \texttt{mpmath} library in Python.
This is accurate but incredibly slow computationally.
To quantify how slow, we found that
evaluating the likelihood defined by~\eq{eq:p_m_bursty+rep} $\sim50$ times
(for a typical dataset of interest from~\cite{Jones2014},
with $m$ values spanning 0 to $\sim50$)
using arbitrary precision arithmetic is 100-1000 fold slower than
evaluating a negative binomial likelihood for the corresponding
constitutive promoter dataset.

To claw back $\gtrsim30$ fold of that slowdown, we can exploit
one of the many catalogued symmetries involving ${_2F_1}$.
The solution involves recursion relations originally explored by Gauss,
and studied extensively in~\cite{Pearson2017, Gil2007}.
They are sometimes known as contiguous relations and relate the values
of any set of 3 hypergeometric functions whose arguments differ by integers.
To rephrase this symbolically, consider a set of hypergeometric functions
indexed by an integer $n$,
\begin{align}
f_n = {_2F_1}(a+\epsilon_i n, b+\epsilon_j n, c+\epsilon_k n; z),
\end{align}
for a fixed choice of $\epsilon_i, \epsilon_j, \epsilon_k \in \{0,\pm 1\}$
(at least one of $\epsilon_i, \epsilon_j, \epsilon_k$ must be nonzero,
else the set of $f_n$ would contain only a single element).
Then there exist known recurrence relations of the form
\begin{align}
A_n f_{n-1} + B_n f_{n} + C_n f_{n+1} = 0,
\end{align}
where $A_n, B_n$, and $C_n$ are some functions of $a,b,c$, and $z$.
In other words, for fixed $\epsilon_i, \epsilon_j, \epsilon_k, a, b,$ and $c$,
if we can merely evaluate ${_2F_1}$ twice, say for $n^\prime$ and $n^\prime-1$,
then we can easily and rapidly generate values for arbitrary $n$.

This provides a convenient solution for our problem: we need repeated
evaluations of ${_2F_1}(a+m, b+m, c+m; z)$
for fixed $a,b$, and $c$ and many integer values of $m$.
They idea is that we can use arbitrary precision arithmetic to evaluate
${_2F_1}$ for just two particular values of $m$ and then generate
${_2F_1}$ for the other 50-100 values of $m$ using the recurrence
relation.\footnote{
There are even more sophisticated ways of utilizing the recurrence
relations that might have netted another factor of 2 speed-up, and
possibly as much as a factor of 10, but the method described here had
already reduced the computation time to an acceptable
$\mathcal{O}(\text{1 min})$, so these more sophisticated approaches did
not seem worth the time to pursue.
}

However, there two further wrinkles.
The first is that
a naive application of the recurrence relation is numerically unstable.
Roughly, this is because the three term recurrence relations,
like second order ODEs, admit two linearly independent solutions.
In a certain eigenbasis, one of these solutions dominates the other
as $n\rightarrow\infty$, and as $n\rightarrow-\infty$,
the dominance is reversed.
If we fail to work in this eigenbasis, our solution of the recurrence relation
will be a mixture of these solutions and rapidly accumulate numerical error.
For our purposes, it suffices to know that the authors of~\cite{Gil2007}
derived the numerically stable solutions (so-called \textit{minimal solutions})
for several possible choices of $\epsilon_i, \epsilon_j, \epsilon_k$.
Running the recurrence in the proper direction using a minimal solution
is numerically robust and can be done entirely in floating point arithmetic, 
so that we only need to evaluate ${_2F_1}$ with arbitrary precision arithmetic
to generate the seed values for the recursion.

The second wrinkle is a corollary to the first.
The minimal solutions are only minimal for certain ranges of the argument $z$,
and not all of the 26 possible recurrence relations
have minimal solutions for all $z$.
This can be solved by using one of the many transformation formulae for
${_2F_1}$ to convert to a different recurrence relation that has
a minimal solution over the required domain of $z$, although
this can require some trial and error to find the right transformation,
the right recurrence relation, and the right minimal solution.

\subsubsection{Particulars}
Let us now demonstrate these generalities for our problem of interest.
In order to evaluate the probability distribution of our
model,~\eq{eq:p_m_bursty+rep}, we need to evaluate hypergeometric functions
of the form ${_2F_1}(\alpha+m, \beta+m, \gamma+m; -b)$
for values of $m$ ranging from $0$ to $\mathcal{O}(100)$.
The authors of~\cite{Gil2007} did not derive a recursion relation
for precisely this case. We could follow their methods and do so ourselves,
but it is much easier to convert to a case that they did consider.
The strategy is to look through the minimal solutions tabulated
in~\cite{Gil2007} and search for a transformation we could apply to
${_2F_1}(\alpha+m, \beta+m, \gamma+m; -b)$ that would place the $m$'s
(the variable being incremented by the recursion)
in the same arguments of ${_2F_1}$ as the minimal solution.
After some ``guess and check,'' we found that the transformation
\begin{align}
{_2F_1}(\alpha+m, \beta+m, \gamma+m; -b)
=
(1+b)^{-\alpha-m}
        {_2F_1}\left(\alpha+m, \gamma-\beta, \gamma+m; \frac{b}{1+b}\right),
\label{eq:rec_euler_pretransform}
\end{align}
produces a ${_2F_1}$ on the right hand side that closely resembles
the minimal solutions $y_{3,m}$ and $y_{4,m}$ in Eq.~4.3 in~\cite{Gil2007}.
Explicitly, these solutions are
\begin{align}
y_{3,m}
&\propto
{_2F_1}\left(-\alpha^\prime + \gamma^\prime - m,
                -\beta^\prime + \gamma^\prime,
                1-\alpha^\prime-\beta^\prime+\gamma^\prime-m;
                1-z\right)
\\
y_{4,m}
&\propto
{_2F_1}\left(\alpha^\prime + m,
                \beta^\prime,
                1+\alpha^\prime+\beta^\prime-\gamma^\prime+m;
                1-z\right),
\label{eq:minimal_soln_sans_prefac}
\end{align}
where we have omitted prefactors which are unimportant for now.
Which of these two we should use depends on what values $z$ takes on.
Equating $1-z=b/(1+b)$ gives $z=1/(1+b)$, and since $b$ is strictly positive,
$z$ is bounded between 0 and 1.
From Eq.~4.5 in~\cite{Gil2007}, $y_{4,m}$ is the minimal solution
for real $z$ satisfying $0<z<2$, so this is the only minimal solution we need.

Now that we have our minimal solution,
what recurrence relation does it satisfy?
Confusingly, the recurrence relation of which $y_{4,m}$ is a solution
increments different arguments of ${_2F_1}$ that does $y_{4,m}$:
it increments the first only, rather than first and third.
This recurrence relation can be looked up, e.g., Eq.~15.2.10
in~\cite{Abramowitz1964}, which is
\begin{align}
(\gamma^\prime - (\alpha^\prime + m)) f_{m-1}
+
(2(\alpha^\prime+m) - \gamma^\prime + (\beta^\prime - \alpha^\prime)z)f_m
+ \alpha^\prime(z-1) f_{m+1} = 0.
\label{eq:chosen_rec_rel}
\end{align}
Now we must solve for the parameters appearing in the recurrence relation
in terms of our parameters, namely by setting
\begin{align}
\begin{split}
\alpha^\prime &= \alpha
\\
\beta^\prime &= \gamma - \beta
\\
1 + \alpha^\prime + \beta^\prime - \gamma^\prime &= \gamma
\\
1 - z &= \frac{b}{1+b}
\end{split}
\end{align}
and solving to find
\begin{align}
\begin{split}
\alpha^\prime &= \alpha
\\
\beta^\prime &= \gamma - \beta
\\
\gamma^\prime &= 1 + \alpha - \beta
\\
z &= \frac{1}{1+b}
.
\end{split}
\end{align}
Finally we have everything we need. The minimal solution
\begin{align}
y_{4,m}
=
\frac{\Gamma(1+\alpha^\prime-\gamma^\prime+m)}
        {\Gamma(1+\alpha^\prime+\beta^\prime-\gamma^\prime+m)}
\times
{_2F_1}\left(\alpha^\prime + m,
                \beta^\prime,
                1+\alpha^\prime+\beta^\prime-\gamma^\prime+m;
                1-z\right),
\end{align}
where we have now included the necessary prefactors,
is a numerically stable solution of the recurrence
relation~\eq{eq:chosen_rec_rel} if the recursion is run
from large $m$ to small $m$.
So the procedure is to compute the value of ${_2F_1}$ for the two
largest $m$ values of interest using arbitrary precision arithmetic,
compute the prefactors to construct
$y_{4,\text{max}(m)}$ and $y_{4,\text{max}(m)-1}$,
recursively compute $y_{4,m}$ for all $m$ less than $\text{max}(m)$ down
to $m=0$, then cancel off the prefactors of the resulting values of
$y_{4,m}$ for all $m$ to produce ${_2F_1}$ for all desired $m$ values.
\mmnote{Maybe I should reformat this paragraph into
a pseudocode version of the algorithm?
Instead of, or in addition to?}

With ${_2F_1}$ computed, the only remaining numerical danger in computing
$p(m)$ in~\eq{eq:p_m_bursty+rep} is overflow of the gamma functions.
This is easily solved by taking the log of the entire expression
and using standard routines to compute the log of the gamma functions,
then exponentiating the entire expression at the end if $p(m)$
is needed rather than $\log p(m)$.

%%%%%%%%%%%%%%%%%%%%% APPENDICES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix


% \bibliographystyle{nature}
\bibliographystyle{abbrv}
\bibliography{./library}

\end{document}
