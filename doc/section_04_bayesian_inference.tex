% !TEX root = ./bursty_transcription.tex
\section{Finding the ``right'' model: Bayesian parameter inference and model 
selection}
\subsection{Parameter inference for constitutive promoters}

From consideration of Fano factors in the previous section, we suspect that
model 5 in Figure~\ref{fig:constit_cartoons}, a one-state bursty model of
constitutive promoters, achieves a Goldilocks level of complexity. Does this
stand up to closer scrutiny, namely, comparison to full mRNA distributions
rather than simply their moments? We will test this thoroughly on
single-cell mRNA counts for different unregulated promoters from Jones et.\
al.~\cite{Jones2014}.

It will be instructive, however, to first consider the Poisson promoter, model 1
in Figure~\ref{fig:constit_cartoons}. As we alluded to earlier, since the
Poisson distribution has a Fano factor $\nu$ strictly equal to 1, and all of
the observed data has Fano factor $\nu>1$, we might already suspect that this
model is incapable of fitting the data. We will verify that this in fact the
case. Using the same argument we can immediately rule out models 2 and 3 from 
Figure~\ref{fig:constit_cartoons}. these models have Fano factors $\nu\le 1$
meaning they are underdisperse relative to Poisson. We will also not explicitly
consider model 4 from~\fig{fig:constit_cartoons} since it was already thoroughly
analyzed in~\cite{Razo-Mejia2020}, and since model 5 can be viewed as a special
case of it.

In performing parameter inference on the single-molecule data
of~\cite{Jones2014}, building a generative model is straightforward. The data
are single-cell mRNA counts, and we assume different cells to be independent and
identically distributed from the underlying generative model. The generative
model for our case is the steady-state mRNA distribution computed from the
master equation under consideration.

\subsubsection{Model 1: Poisson promoter}
% \mmnote{A lot of the details I've written here might be excessive for main text and serve better as an intro-by-example to Bayes in the appendix, then reduce main text to a bit more bare bones?}
For this model the master equation of interest is
Eq.~\ref{eq:poisson_promoter_cme} with repressor set to zero, i.e.,
\begin{equation}
\deriv{t}p_{m,U}(t) = rp_{m-1,U}(t) - rp_{m,U}(t)
        + (m+1)\gamma p_{m+1,U}(t) - \gamma p_{m,U}(t),
\end{equation}
whose steady-state solution is given by a Poisson distribution with parameter
$\lambda \equiv r / \gamma$. This steady state distribution defines the
likelihood $p(m\mid\lambda)$ for our Bayesian inference, i.e. 
\begin{equation}
p(m\mid\lambda) = \frac{\lambda^m e^{-\lambda}}{m!}
\label{eq:poisson_inference010}
\end{equation}
is the probability of observing a single cell with $m$ mRNAs given a value of
$\lambda$, written to make the conditioning explicit.

With our likelihood in hand, we can invoke Bayes theorem to write down the
posterior distribution on our model parameter $\lambda$, given by
\begin{equation}
p(\lambda\mid D) \propto p(D\mid\lambda) p(\lambda),
\end{equation}
where our data $D=\{m_1, m_2,\dots, m_N\}$ is a list of mRNA counts over a
population of $N$ identical cells. As is standard we have neglected the factor
$p(D)$ on the right hand side since it is independent of $\lambda$ and serves
only as a normalization factor. Since we assume each cell's mRNA count is
independent of others, the likelihood of the full inference problem
$p(D\mid\lambda)$ is simply a product of the single cell likelihoods given by
\eq{eq:poisson_inference010} above, so
\begin{equation}
p(D\mid\lambda) = \prod_{k=1}^N \frac{\lambda^{m_k}e^{-\lambda}}{m_k!}.
\end{equation}
This is often notated simply as
\begin{equation}
D \sim \text{Poisson}(\lambda),
\end{equation}
which is read as the data $D$ is Poisson distributed with mean $\lambda$. The
$\sim$ operator literally denotes ``is distributed according to.'' The
conditioning on $\lambda$ is no longer explicitly notated, only implied by its
appearance on the right hand side.

To proceed we need to specify a prior. In this case we are extremely data-rich,
as the dataset from Jones et.\ al~\cite{Jones2014} has of order 1000-3000
single-cell measurements for each promoter, so our choice of prior matters
little here, as long as it is sufficiently broad. For details on the prior 
selection we refer the reader to Appendix~\ref{sec:bayesian}. For our
purpose here it suffices to specify that we use a prior of the form $\lambda
\sim \text{Gamma}(\alpha, \beta)$. Putting a gamma prior on $\lambda$ introduces
two new parameters $\alpha$ and $\beta$ which parametrize the gamma distribution
itself, which we use to encode the range of $\lambda$ values we view as
reasonable. Recall $\lambda$ is the mean steady-state mRNA count per cell, which
\textit{a priori} could plausibly be anywhere from 0 to a few hundred.
$\alpha=1$ and $\beta=1/50$ achieve this, since the gamma distribution is
strictly positive with mean $\alpha/\beta$ and standard deviation
$\sqrt{\alpha}/\beta$.

As detailed in Appendix~\ref{sec:bayesian} this particular choice of prior
known as the \textit{conjugate} prior for a Poisson likelihood allows us to 
get a closed form for the posterior distribution $p(\lambda \mid D)$. In 
particular it can be shown that~\cite{Gelman2013}
\begin{equation}
\lambda
\sim \text{Gamma}\left(\alpha + \bar{m}N, \beta + N\right),
\end{equation}
where we defined the sample mean $\bar{m} = \frac{1}{N}\sum_k m_k$ for
notational convenience. Furthermore given that $N$ is $\mathcal{O}(10^3)$ and
$\langle m\rangle \gtrsim 0.1$ for all promoters measured in~\cite{Jones2014}
our data easily overwhelms the choice of prior, and allows us to make the 
excellent approximation 
\begin{equation}
\lambda
\sim \text{Gamma}\left(\alpha + \bar{m}N, \beta + N\right)
\approx \text{Normal}\left(\bar{m}, \sqrt{\frac{\bar{m}}{N}}\right).
\end{equation}
As an example with real numbers, for the \textit{lacUV5} promoter, Jones et.\
al~\cite{Jones2014} measured 2648 cells with an average mRNA count per cell of
$\bar{m} \approx 18.7$. In this case then, our posterior is
\begin{equation}
\lambda
\sim \text{Normal}\left(18.7, 0.08\right),
\label{eq:posterior_poisson}
\end{equation}
which suggests we have inferred our model's one parameter to a precision of
order 1\%.

\mrm{
We alert the reader not to confuse a tightly constrained posterior distribution
with a good generative model. In other words, not because the single parameter
for our Poisson likelihood can only take a small range of values constrained by
the data, this implies that such Poisson distribution characterizes the
underlying cell-to-cell variability we observe in the data. To systematically
check the validity of the generative model we can make use of \textit{posterior
predictive checks}. These consists on generating synthetic data using our
generative model for many plausible values of our parameter. For the case of our
\textit{lacUV5} promoter this means that we sample a value for $\lambda$ out of
the posterior distribution (Eq.~\ref{eq:posterior_poisson}), and generate 2648
samples out of a Poisson distribution with such $\lambda$ value. We then repeat
this procedure 1000 times. Clearly if those data appear quite different, the
model has a problem. Put another way, if we suppose the generative model is
true, then the synthetic datasets we generate should resemble the actual
observed data, and if not, it suggests the model is missing important features.}

\mrm{
To compare so many samples with the actual observed data, we can use empirical
cumulative distribution functions (ECDF) of the distribution quantiles. This 
representation is shown in Figure~\ref{fig:constit_post_full}(B). In this 
example, the median for each possible mRNA count for the Poisson distribution
is shown as a dark green line, while the lighter green contains 95\% of the
posterior predictive samples. This way of representing the posterior predictive
checks gives us a sense of the range of data we might consider plausible, under
the assumption that the model is true. In this case it is quite obvious that the
observed data, plotted in orange, could not plausibly come from this Poisson
generative model. We will cover the other model shown in
Figure~\ref{fig:constit_post_full}(B) next.
}

\subsubsection{Model 5 - Bursty promoter}
Let us now consider the problem of parameter inference from FISH data for model
five from~\fig{fig1:means_cartoons}(C). As derived in
Appendix~\ref{sec:gen_fcn_appdx}, the steady-state mRNA distribution in this
model is a negative binomial distribution, given by
\begin{equation}
p(m) = \frac{\Gamma(m+k_i)}{\Gamma(m+1)\Gamma(k_i)}
        \left(\frac{1}{1+b}\right)^{k_i}
        \left(\frac{b}{1+b}\right)^m,
\label{eq:neg_bionom}
\end{equation}
where $b$ is the mean burst size and $k_i$ is the burst rate nondimensionalized
by the mRNA degradation rate $\gamma$. As sketched earlier, the story of this
distribution is of geometrically-distributed bursts of mRNA, where the arrival
of bursts is a Poisson process with rate $k_i$ and the mean size of a burst is
$b$.

As for the Poisson promoter model, this expression for the steady-state mRNA
distribution is exactly the likelihood we want to use in Bayes theorem. Again
denoting the single-cell mRNA count data as $D=\{m_1, m_2,\dots, m_N\}$, here
Bayes theorem takes the form
\begin{equation}
p(k_i, b \mid D) \propto p(D\mid k_i,b)p(k_i, b).
\end{equation}
We already have our likelihood --the product of $N$ negative binomials as
Eq.~\ref{eq:neg_bionom}--  so we only need to choose priors on $k_i$ and $b$.
For the datasets from~\cite{Jones2014} that we are analyzing, as for the Poisson
promoter model above we are still data-rich so the prior's influence remains
weak, but not nearly as weak because the dimensionality of our model has
increased from one to two.
\mrm{
Details on the arguments behind our prior distribution selection are left for
Appendix~\ref{sec:bayesian}. Our full generative model can be specified as
\begin{equation}
\begin{split}
\ln k_i \sim \text{Normal}(-0.5, 2) \\
\ln b \sim \text{Normal}(0.5, 1) \\
m \sim \text{NBinom}(k_i, b).
\end{split}
\end{equation}
Note that we specify a distribution over the logarithm of our parameters $k_i$
and $b$. This is commonly the case for parameters for which our previous 
knowledge based on our domain expertise spans several orders of magnitude.
}

We carried out MCMC sampling on the posterior of this model, starting with the
constitutive \textit{lacUV5} dataset from~\cite{Jones2014}. The resulting MCMC
samples are shown in~\fig{fig:constit_post_full}(A). In contrast to the
active/inactive constitutive model considered in~\cite{Razo-Mejia2020}
(nonequilibrium model 4 in~\ref{fig:constit_cartoons}), this model is
well-identified with both parameters determined to a fractional uncertainty of
5-10\%. The strong correlation reflects the fact that their product sets the
mean of the mRNA distribution, which is tightly constrained by the data, but
there is weak ``sloppiness''~\cite{Transtrum2015} along a set of values with a
similar product.

Flush with success having found the model's posterior to be well-identified, the
next step is posterior predictive sampling. The only procedural difference
compared to the Poisson promoter model is that, since we have no analytical
posterior expression but only samples from the posterior, we generate a
synthetic dataset (i.e., posterior predictive samples) for each posterior sample
from the MCMC sampling. \fig{fig:constit_post_full}(B) shows the resulting
predictive ECDF; similarly to the Poisson promoter model, the median posterior
predictive ECDF is plotted as a dark blue line, while a lighter blue shaded
region encompasses 95\% of the posterior predictive samples. Unlike the Poisson
promoter model, the experimental ECDF closely tracks the posterior predictive
ECDF, indicating this model is actually able to generate the observed data and
increasing our confidence that this model is at least not wrong.

\textit{lacUV5} is our primary target here, since it forms the core of all the
simple repression constructs of~\cite{Jones2014} that we consider in
Section~\ref{sec:rep_kinetics_inference}. Nevertheless, we thought it wise to
apply our bursty promoter model to the other 17 unregulated promoters available
in the single-cell mRNA count dataset from~\cite{Jones2014} as a test that the
model is capturing the essential phenomenology. If the model fit well to all the
different promoters, this would increase our confidence that it would serve well
as a foundation for inferring repressor kinetics later in
Section~\ref{sec:rep_kinetics_inference}. Conversely, were the model to fail on
more than a couple of the other promoters, it would give us pause.

\begin{figure}%[h!]
\centering
\includegraphics[width=\textwidth]{../figures/main/fig03.pdf}
\caption{\textbf{Constitutive promoter posterior inference and model
comparison.} (A) The joint posterior density of model 5, the bursty promoter
with negative binomially-distributed steady state, is plotted with MCMC samples.
1D marginal probability densities are plotted as flanking histograms. The model
was fit on \textit{lacUV5} data from~\cite{Jones2014}. (B) The empirical
distribution function (ECDF) of the observed population distribution of mRNA
transcripts under the control of a constitutive \textit{lacUV5} promoter is
shown in orange. The median posterior predictive ECDFs for models (1), Poisson,
and (5), negative binomial, are plotted in dark green and dark blue,
respectively. Lighter green and blue regions enclose 95\% of all posterior
predictive samples from their respective models. Model (1) is in obvious
contradiction with the data while model (5) is not. single-cell mRNA count data
is again from~\cite{Jones2014}. (C) Joint posterior distributions for burst rate
$k_i$ and mean burst size $b$ for 18 unregulated promoters
from~\cite{Jones2014}. Each contour indicates the 95\% highest posterior
probability density region for a particular promoter. Note that the vertical
axis is shared with (D). (D) Plots of the burst rate $k_i$ vs.\ the binding
energy for each promoter as predicted in~\cite{Brewster2012}. The dotted line
shows the predicted slope according to $\ln k_i/\gamma \sim \text{constant} -
\beta\Delta\varepsilon_P$, described in text. Each individual promoter is
labeled with a unique number in both (C) and (D) for cross comparison.}
\label{fig:constit_post_full}
\end{figure}

\fig{fig:constit_post_full}(C) shows the results, plotting the posterior
distribution from individually MCMC sampling all 18 constitutive promoter
datasets from~\cite{Jones2014}. To aid visualization, rather than plotting
samples for each promoter's posterior as in \fig{fig:constit_post_full}(A), for
each posterior we find and plot the curve that surrounds the 95\% highest
probability density region. What this means is that each contour 
encloses approximately 95\% of the samples, and thus 95\% of the probability
mass, of its posterior distribution. Posterior predictive ECDFs (not shown)
display a similar level of agreement between data and predictive samples as for
the bursty model with \textit{lacUV5} in \fig{fig:constit_post_full}(B).
\mmnote{Might be worth showing some/all of these PPCs in supplement for
completeness? We could do postage stamp sized diff plots and probably fit all 18
promoters on 1-2 pages.}\mrm{Definitely need to show them in SI.}

One interesting feature from \fig{fig:constit_post_full}(C) is that burst rate
varies far more widely, over a range of $\sim10^2$, than burst size, confined to
a range of $\lesssim10^1$ (and with the exception of promoter 6, just a span of
3-5x). This suggests that $k_i$, not $b$, is the key dynamic variable that
promoter sequence tunes.

It is interesting to connect this observation to the work
of~\cite{Brewster2012}, where these same 18 promoters were considered through
the lens of the three-state equilibrium model (model 2 in
Figure~\ref{fig1:means_cartoons}(B)) and binding energies $\Delta\varepsilon_P$
were predicted from an energy matrix model derived from~\cite{Kinney2010}. As
previously discussed the thermodynamic models of gene regulation can only make
statements about the mean gene expression. This implies that we can draw the
connection between both frameworks by equating the mean mRNA $\left\langle m \right\rangle$. This results in
\begin{equation}
\langle m \rangle = \frac{k_i b}{\gamma}
        = \frac{r}{\gamma}
        \frac{\frac{P}{N_{NS}}\exp(-\beta\Delta\varepsilon_P)}
                {1+\frac{P}{N_{NS}}\exp(-\beta\Delta\varepsilon_P)}.
\end{equation}
By taking the weak promoter approximation for the equilibrium model ($P/N_{NS} 
\exp(-\beta\Delta\varepsilon_r \ll 1)$) results in
\begin{equation}
\langle m \rangle = \frac{k_i b}{\gamma}
        = \frac{r}{\gamma} \frac{P}{N_{NS}}\exp(-\beta\Delta\varepsilon_P),
\end{equation}
valid for all the binding energies considered here.

Given this result, how are the two coarse-grainings related? The only
association that makes dimensional sense and produces the correct
order-of-magnitude for the known parameters is to take
\begin{equation}
\frac{k_i}{\gamma} = \exp(-\beta\Delta\varepsilon_P)
\label{eq:bursty_equil_corresp1}
\end{equation}
and
\begin{equation}
b = \frac{r}{\gamma}\frac{P}{N_{NS}}.
\label{eq:bursty_equil_corresp2}
\end{equation}
Figure~\ref{fig:constit_post_full}(D) shows that this linear scaling between
$\ln k_i$ and $-\beta\Delta\varepsilon_P$ is approximately true for all 18
constitutive promoters considered. The intercept is an uninteresting function of
the unknown model parameters, so we only consider the slope of the scaling in
\fig{fig:constit_post_full}(D).
\mmnote{Wait, is that true or can we do something with the intercept, related to the burst size in some useful way? Needs more careful thought.}

While the associations represented by
Eq.~\ref{eq:bursty_equil_corresp1} and Eq.~\ref{eq:bursty_equil_corresp2}
appear to be born out by the scaling $\ln k_i \sim -\beta\Delta\varepsilon_P$,
we do not find the association of parameters encoded by
\eqrange{eq:bursty_equil_corresp1}{eq:bursty_equil_corresp2}
intuitive. If some deeper insight is waiting to be gleaned from it, we leave it
as an open problem.

\mmnote{Outline, still to cover:
\begin{itemize}
\item All 18 promoters. Hey the model still works on things other than UV5,
cool. Interesting and somewhat counterintuitive scaling b/w burst rate and
binding energy. Puzzle in comparing w/ Chong2014 supercoiling model. Are we
missing important things?? Unclear, we leave as open question. Good enough for
our purposes: posterior is identifiable, PPC is great, and of the models we've
thought of it is unique in satisfying both.
\end{itemize}
}

\mmnote{Discuss puzzling comparison w/ Chong2014: if supercoiling is the thing, why are my burst sizes all the same but burst rates vary? And why is the duty cycle of my promoter so low, ie., bursts so short? COmpare their fig 7E; their $\beta/\alpha$ is my $k^+/k^-$. They have one or two genes with very small $\beta/\alpha$, does the \textit{galK} locus just happen to be that, or is there a deeper disagreement? Hard to say w/o more data.}

\subsection{Transcription factor kinetics can be inferred from FISH measurements}
\label{sec:rep_kinetics_inference}
\mmnote{Outline:
\begin{itemize}
\item Full model. Write Bayes, handwave 2F1 dist story in limits of weak,
strong, and intermediate repression.
\item Hey look it mostly works. With full model, 9D model is well identified,
though most of the individual experiments unsurprisingly are not: only the ratio
of repressor rates is identifiable. PPC is not perfect, it kinda misses some
rep/op pairs but overall it's surprisingly predictive considering how strong
were the assumptions that went into it.
\item Do we chalk this up to experimental imperfections or is there interesting
biology to be found in the disagreements? I'm inclined towards the former. Even
just catching cells in truly apples-to-apples growth phases, or matching up
parameters of imaging sessions weeks or months apart, is hardly trivial.
\item The alternative is to refine our model and/or add on complexity, and it's
not at all clear what additions to make to the model, especially how to produce
the long tail of repressed strains over UV5. I see no way to get that without
getting into complicated time-correlation/history effects, where
transcription...rebounds?? After being repressed?? Sounds odd.
\item Comparison between my inferred rates, equilibrium binding E, and
single-molecule measurements. Not quite as slam-dunk as I'd hoped because of
$\gamma$ dependence, but rates are w/in factor of 2 or better, seems quite good
really! With exception of one Oid data data point, free energies are w/in about
0.5 kT also. That's not massively larger than the repeatability threshold of
fold-change measurements, at maybe 0.1 to 0.3 kT.
\item Surprising that so many model parameters can be inferred from just a few
distributions that, by eye, don't have strong features! Does require some
assumptions, e.g., about equivalence of rates across experiments, but that seems
quite reasonable.
\end{itemize}
}

\fig{fig3:kR_inferences} presents inferred
transcription factor rates, compares them to
single-molecule measurements, and compares their ratios to gold-standard binding
energies.
\begin{figure}%[h!]
\centering
\includegraphics[width=0.9\textwidth]{../figures/fig3/fig3.ai}
\caption{\textbf{Simple repression model comparison.}
Panel (A) depicts the cartoon of simple repression for which we infer parameters.
\mmnote{Not sure panel (A) is necessary, we've already shown it in at least 2
other figs. We could instead show some alternative slices of 9D posterior as a
companion to (B), or something totally different\dots??}
(B) Contours which enclose 50\% and 95\% of the posterior
probability mass are shown for of several 2D slices of
the 9D posterior distribution, from fitting one
unbinding rate for each operator (O1, O2, O3) and one binding rate for each aTc
concentration (corresponding to an unknown mean repressor copy number). (C)
Ratios of our inferred unbinding rates are compared with operator binding energy
differences measured in Garcia \& Phillips 2011 (triangles) and Razo-Mejia et.\
al.\ 2018 (squares). (D) Unbinding rates inferred in this work are compared with
single-molecule measurements of the same from Hammar et.\ at.\ 2014
\mmnote{Johan Elf's group}. Values are of similar order of magnitude, but a
precise quantitative comparison unfortunately depends sensitively on the assumed
mRNA lifetime, which was not measured.}
\label{fig3:kR_inferences}
\end{figure}

\begin{figure}%[h!]
\centering
\includegraphics[width=0.9\textwidth]{../figures/figSIxx/ppc_many_pooled.pdf}
\caption{\textbf{Posterior predictive checks.}
(A) The posterior distribution from~\fig{fig3:kR_inferences}B is
shown again for context. (B), (C), and (D) Samples from the
posterior predictive distribution are shown for each of the datasets
used in the inference. Samples are sorted by operator and plotted separately
simply for visual clarity. The unrepressed promoter, UV5, is shown with each as
a reference point. \mmnote{Obviously the PPC is not perfect, but considering the
relative simplicity of the model, I'm pleasantly surprised how well it worked
and that the model was even identifiable at all. Interestingly, and perhaps not
surprisingly, only 3 of the 9 datasets were identifiable if fit in isolation:
otherwise, it was only by making assumptions that certain rates are equal across
datasets was identifiability achieved.}}
\label{fig4:ppc}
\end{figure}